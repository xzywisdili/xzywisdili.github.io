<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>分享 on XZY&#39;s BLOG</title>
    <link>https://www.xzywisdili.com/tags/%E5%88%86%E4%BA%AB/</link>
    <description>Recent content in 分享 on XZY&#39;s BLOG</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 07 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.xzywisdili.com/tags/%E5%88%86%E4%BA%AB/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ADSL 数据集的建立：练习示例</title>
      <link>https://www.xzywisdili.com/post/2023-05-08-adslexample/</link>
      <pubDate>Sun, 07 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-05-08-adslexample/</guid>
      <description>总结 通过一则创立 ADSL 数据集的练习示例加深对 ADSL 数据集的理解； ADSL（Subject-Level Analysis Data Set） 是 ADaM 中的一种数据集，特点是每一行是一个单独患者的记录（类似 SDTM 中的 DM 数据集），主要包括的变量有：
Demographic 相关的变量； 计划和实际的 Treatment 相关变量； 是否为 &amp;ldquo;Safety&amp;rdquo; 的患者标识 flag ADSL 的建立过程中，一般需要从 SDTM Domain 中的数个数据集合并而来：
DM 中的大部分变量 EX (Exposure)，DS (Disposition) 和其他 SDTM Domain ADSL 的结构 ADSL 的结构是一行记录代表一个患者，包括 Identifier，Demographics, Population flags, treatment, dose 和其他 subject-level 的变量。下面一一进行分析。
Identifier 变量 STUDYID, USUBJID, SUBJID, SITEID，在存在于 DM 中； Subject Demographics 变量 AGE：DM.AGE，如果分析需要 derive 一个 age 出来，需要添加 AAGE 变量； AGEU、SEX、RACE：都从 DM 中合并过来； Population Flag 变量 FASFL：全分析数据集的标识 SAFFL：Safety Population 的标识 Dose 变量 TRTSDT、TRTSDTM：分别是 Treatment 中第一次服药的日期和日期时间； TRTxxSDTF：xx一般是两位数字，代表第几个阶段，也就是第几个阶段的TRT； TRTSDTF：第一次服药的标识。 Subject-Level Trial Experience 变量 EOSDT：研究结束的日期 EOSSTT：研究结束的状态，比如取值“COMPLETED” 阅读和熟悉 ADSL 的 Spec 熟悉 ADSL 的 Spec，对于我们初学制作 ADSL 的合并数据集过程非常有帮助。</description>
    </item>
    
    <item>
      <title>CDISC 标准（五）——ADaM 标准概述</title>
      <link>https://www.xzywisdili.com/post/2023-05-02-cdiscnotes5/</link>
      <pubDate>Tue, 02 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-05-02-cdiscnotes5/</guid>
      <description>总结 ADaM 标准实为了让临床试验统计分析人员梗快速、标准准确地进行统计分析和制作报表的标准； ADaM 主要分为三类数据集：ADSL，BDS 和 OCCDS； 详细梳理了三类数据集的特点以及对应的重点变量。 ADaM 数据集是做什么用的？ ADaM，Analysis Data Model，顾名思义，为了更加方便、标准且准确地进行统计分析，输出相关统计图表的标准模型。
临床实验的流程包括：实验设计，得到原始数据 → 经过 SDTM 标准化得到标准数据 → 将 SDTM 标准数据转化为 ADaM 标准数据 → 使用 ADaM 数据集生成统计图表 → 撰写药物上市申请文档。
在这个工作流程中：
SDTM 标准更偏向于数据标准化； 不同实验的数据集，结构内容和变量基本大部分相同； 如果直接从 SDTM 数据集创建统计图表，需要增加大量计算语句，非常冗杂并且容易出错； ADaM 标准更偏向于数据的可分析性； 数据集的变量可以根据实验的不同进行调整，更加灵活； 更加方便快捷、标准、准确地编写统计图表生成的语句。 跟 SDTM IG 文件类似，ADaM 也有对应的 IG（Implementation Guide） 文件，在 CDISC 的官网就可以找到。
ADaM 有五大基础原则 清晰且无歧义，Clearly adn unambiguously，有标准则需要与标准一致，如果没有标准就需要描述清晰； 可追溯性，Traceability，每个变量，每条记录的来源，都必须能从对应的 SDTM 数据集中找到； 能够被常用的统计软件 SAS 使用； 必须具备 metadata 元数据，即必须把 ADaM 中每个变量的意义放在一个元数据文件中； 即分析性 analysis-ready，使用最少的编程工作就可以完成分析任务；ADaM 数据可以只包含分析所需要的数据，如果收集了一些原始数据并不会用于分析中，那么就不需要纳入 ADaM 数据集中。 可追溯性 可追溯性非常重要，它要求所有数据有依可查，而不是凭空产生。这样可以方便分析人员和审阅者查看数据的产生过程，排除可能存在的异常数据。可追溯性分为以下两点：</description>
    </item>
    
    <item>
      <title>CDISC 标准（四）——SDTM 数据集详细分类</title>
      <link>https://www.xzywisdili.com/post/2023-05-02-cdiscnotes4/</link>
      <pubDate>Tue, 02 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-05-02-cdiscnotes4/</guid>
      <description>总结 本笔记的主要内容：
介绍 SDTM 标准下的七个大类别，以及主要包括的数据集； 梳理两个最重要的数据集：AE（副作用数据集）和 LB（实验室检测结果数据集）。 SDTM 的全称是 SDTM Standard dataset tabulation model，即实验数据标准化的模型，在之前的笔记中有一个概述的介绍。SDTM 标准力图能够尽可能覆盖在临床实验进行过程中所需要收集到的所有数据和相关信息，因此也详细地设计了各种不同分类的大类别和数据集。
在这个分类下，总共包括七个大类别和 44 个数据集。每一种数据集都属于唯一一个类别。七个大类别“SIFEFTR”：
特殊目的类：Special Purpose 干涉类：Intervention 发现类：Findings 发现相关类：Findings About 事件类：Events 实验设计类：Study Trial 关系类：Relationship 下面分门别类介绍每一种类型。
特殊目的类 Special Purpose 特殊目的类：包括和实验参与者本人相关的数据，无法归类到其他类别。主要包括以下几个数据集：
CO：评价数据集，Comments**，医生手写或者补充的文本备注和记录，需要与其他数据集相连接；如果手写的记录超过 CDISC 规定的最长值长度 200 个字符，就需要创建新的 COVAL1，COVAL2 变量保存字符，以此类推，每个变量容纳 200 个字符； DM：人口统计学，Demographics，用于保存患者的基础信息，比如患者编号、性别、国籍、种族、实验开始时间等等，在之前的内容中有所记录； SV：患者来访数据，Subject Visit SE，患者时期元素，Subject Element 一个患者在整个临床实验过程中需要来访多次。一般是从 Screen 和纳入开始，之后的来访依次是基线，第一次来访，第二次来访等，直到实验结束。在服用药物过后，因为药物在人体内有残留期，也需要几次患者来访，来观察是否具有副作用和其他治疗效果。 患者来访的时间数据都需要记录在 SV 数据集中。每个患者在实验过程中经历的每个时期和元素的时间信息，这些数据被放在 SE 中。 干涉类 Interventions 干涉类主要包括对患者有影响的行为的相关数据，包括以下几个数据集：
CM：伴随用药 Concomitant and prior medications 参加临床实验的患者，如果有其他疾病，需要服用已经上市的药物，就需要在数据集中记录伴随用药的相关信息；如果是和癌症相关的临床实验，可能需要让受试者服用一种统计的抗癌药物，再服用待实验的药物，那么这个统一服用的药物也需要放置在 CM 数据集中； CM 数据集存放患者服用的其他药物（非本实验药物）的名称、类别、剂量、计量单位、频率、药物类型（胶囊/饮剂）等数据； EX：实验用药 Exposure 实验计划中药物的使用情况； 根据实验设计来确定，核心变量包括 EXTRT（药物的名称），EXDOSE（药物的剂量），EXDOSU（药物剂量的单位），EXDOSFRQ（药物按此剂量服用的频率） 和 EXDOSFRM（药物的形式，液体/胶囊/含服片）； EC：实际实验用药 Exposure as Collected 实际中**药物的使用情况 由 ECOCCUR 变量指定该次是否服药，ECDOSE 记录剂量，ECDOSU 记录剂量单位； EC 和 EX 数据集的结构基本相同，实际分析使用 EX 数据集，因为根据实验设计而来的 PR：过程 Procedures 患者治疗和诊断相关的过程 比如患者参与心血管相关的临床实验，中间去口腔科诊断并拔了智齿，这个过程无法判断是否与临床实验相关，所以也要记录下来。 核心变量：PRTRT，记录做的手术名称 PRSTDTC，PRENDTC，PRSTDY，PRENDY 分别对应手术开始的日期和结束的日期，以及对应的天数； SU：物质使用 Substance Use 其他非药物的物质的使用情况，比如最常见的咖啡（含有咖啡因），吸烟、喝酒； 主要包括以下几个变量：SUTRT（使用物质的名称，包括 CIGARETTES，COFFEE）、SUCAT（使用物质所属的大类）、SUDOSE（这些物质使用的数量）、SUDOSEU（使用物质的数量单位）、SUDOSFRQ（使用物质的频率）、SUSTAT，SUREASND（数值没有被记录和没有记录的原因） 事件类 Events 事件类，代表计划之外的事件，总共包括 6 个数据集：</description>
    </item>
    
    <item>
      <title>SAS 几个重要概念辨析</title>
      <link>https://www.xzywisdili.com/post/2023-05-01-sasnotes1/</link>
      <pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-05-01-sasnotes1/</guid>
      <description>进行变量类型转换，用 input 还是 put 在 SAS 编程过程中，往往会遇到需要转换变量的需求。而转换变量，往往需要考虑使用 INPUT 还是 PUT。那么这时候就要想想几个变量转换中的几个关键点：
源变量是字符型还是数值型？ 如果源变量是字符型，那么值是字符还是数字？ 想要转换后的变量是字符型还是数值型？ 那么，根据这三个问题的答案，就可以推出是使用 INPUT 还是 PUT，他们分别有以下几个特点：
PUT() 永远创建字符型变量； PUT() 中的格式参数必须和源变量类型匹配； INPUT() 的源变量必须为字符型变量； INPUT() 可以根据指定的格式，选择创建字符型或者数值型变量。 下面是几个例子：
需求 代码 源变量类型 源变量值 返回变量类型 返回变量值 PUT 将字符变量转换为字符变量 PUT(name, $10.); 字符型 &amp;lsquo;Richard&amp;rsquo; 永远是字符型 &amp;lsquo;Richard &#39; PUT 将数值变量转换为字符变量 PUT(age, 4.); 数值型 30 永远是字符型 &amp;rsquo; 30&amp;rsquo; PUT 将自定义格式转换为字符变量 PUT(name, $nickname.); 字符型 &amp;lsquo;Richard&amp;rsquo; 永远是字符型 &amp;lsquo;Rick&amp;rsquo; INPUT 将值为数字的字符型变量转换为数值变量 INPUT(agechar, 4.); 永远是字符型 &amp;lsquo;30&amp;rsquo; 数值型 30 INPUT 将值为数字的字符型变量转换为字符变量 INPUT(agechar, $4.); 永远是字符型 &amp;lsquo;30&amp;rsquo; 字符型 &amp;rsquo; 30&#39; 都用于分类变量：class 与 by 的辨析 SAS中的 BY 语句和 CLASS 语句都允许指定一个或多个分类变量。主要区别在于：</description>
    </item>
    
    <item>
      <title>CDISC 标准（三）——SDTM 标准初试</title>
      <link>https://www.xzywisdili.com/post/2023-04-30-cdiscnote3/</link>
      <pubDate>Sun, 30 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-04-30-cdiscnote3/</guid>
      <description>总结 第一次尝试仔细阅读 SDTM IG 文件中的一个 domain 变量信息； 通过 SAS 代码初试按照 SDTM 标准输出标准化的数据集。 本章要开始使用 SAS，并结合 SDTM 标准，看看如何让目标数据集符合 IG 文件里面的标准。
使用的目标 Domain 是 IG 文件 64-65 页介绍的，最重要的 Domain 之一—— DM Domain，具体变量说明表如下：
DM 是 Demographics 的缩写，代表人口统计学信息。所有人类参与的临床实验都需要 DM Domain，内容包括实验参与者的年龄、性别、种族、国籍、实验分组、实验开始日期和结束日期等等等等数据。
DM 数据集往往是接手某个项目最先阅读的数据集，可以查看和了解参与实验的患者的所有信息。在临床实验中，有几个患者参与，那么 DM 数据集中就需要包括几条观测数据。比如，有 10 名患者参与了临床实验，收集了原始数据，那么 DM Domain 中就应该包括 5 条观测。
接下来就是初学 SDTM 标准的学习方法：仔细阅读 SDTM IG 文件中对于每一条变量的说明，并且按照对应的要求，在 SAS 中处理数据集。处理过程中，需要注意以下几个重点：
注意每一条变量的 Type，字符型或者数值型，一定要在 SAS 中按照对应的格式存储，不符合的需要进行转换（INPUT 或者 PUT）； 日期型的变量一定要注意按照规定的 ISO8601 格式； 变量顺序和变量的 Label 要按照表中规定的要求； 多多检查。 从 SDTM IG 表慢慢看起：</description>
    </item>
    
    <item>
      <title>CDISC 标准（二）——SDTM 标准概述</title>
      <link>https://www.xzywisdili.com/post/2023-04-29-cdiscnote2/</link>
      <pubDate>Sat, 29 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-04-29-cdiscnote2/</guid>
      <description>总结 介绍了 SDTM 和 IG 文件的基本概念； 通过阅读 SDTM IG 文件，了解 Domain 和 Variable 的各种信息； 重点是 Variable 的五种分类：Identifier, Topic, Qualifier, Timing, Rule。 SDTM 的基本概念 SDTM（Study Data Tabulation Model）是一个服务于临床实验的标准数据指标模型，也是被业界和 FDA 广泛采用的标准。它规定了在临床实验中，原始数据收集之后的标准化的呈现方式。可能不同种类的药物，在实验中收集的数据样式是不一样的，但是经过 SDTM 标准化之后，相同类别的数据一定是相同的。
标准化的好处是，可以更好地服务于药物开发全链条中的各方人员，大大降低了沟通成本，提高审查部门的审核效率。经过多年的数次更新，SDTM 标准已经几乎可以涵盖所有类型的临床实验数据格式。
而 SDTM IG 文件（SDTM Implementation Guide）中就详细说明了所有 SDTM 标准化数据的方方面面的信息。想要了解 SDTM，就必须要从阅读 SDTM IG 文件开始。
从阅读 SDTM IG 文件开始 SDTM IG 文件可以从 CDISC 组织的官网中免费获得。官网下载得到的是英文版本，虽然民间存在个人翻译的中文版本，但还是推荐采用原汁原味的英文版本进行阅读。同时，官网还提供了 PDF 和 HTML 的多种格式，方便阅读。
Domain 域 在第二章 Fundamentals of the SDTM 中，向我们介绍了 SDTM 标准中的基础元素：Domain（域）。每个 Domain 可以理解为围绕一个主题，相关的所有观测和变量组成的数据集，其中有一些基础的通用要求：</description>
    </item>
    
    <item>
      <title>博客的新浪图床图片崩了？简单办法教你解决！（2023年4月有效）</title>
      <link>https://www.xzywisdili.com/post/2023-04-28-saveyourblogpics/</link>
      <pubDate>Fri, 28 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-04-28-saveyourblogpics/</guid>
      <description>今天偶然翻看以前的博客，突然发现图片都显示不出来了，第一时间想到可能是以前用的图床出了问题。
果不其然，经过查找和检索网上信息，发现新浪图床从去年某个时间开始，限制了外部链接的访问。这就导致了，如果是在自己的博客站上使用了新浪的图床，会导致无法访问（403）。
这时候，不要慌，你的图片并没有丢！网上也提供了很多方法，教你怎么能够重新访问这些图片。我这里推荐一个亲测好用的方法。
第一步：查看你的新浪图床外链链接 按照如下表格修改你的外链链接：
图床链接前缀 修改之后 wx1 tva1 wx2 tva2 wx3 tva3 wx4 tva4 ww1/2/3/4 不用改 tva1/2/3/4 不用改 tvax1/2/3/4 不用改 第二步：通过修改之后的链接找回图片 这时候需要使用外面的托管服务：https://i0.wp.com/ + 你的图床链接。
举例：现在的图床链接是：tva1.sinaimg.cn/large/006tNbRwgy1g9qkc9s187j30pd0nlgqq.jpg，那么代入上述网址之后的链接就变成：
https://i0.wp.com/tva1.sinaimg.cn/large/006tNbRwgy1g9qkc9s187j30pd0nlgqq.jpg
下载下来之后，再迁移到新的图床上就好了，我目前选择的新图床是 sm.ms。
如果以前的图片很多，可以考虑自己写代码批量转换迁移，少的话自己手动也可以完成。
不过需要给自己提个醒了，没有 100% 永远保证稳定的图床服务，对于重要的图片，还是需要在本地备份。</description>
    </item>
    
    <item>
      <title>5 分钟简单生成指定形状的词云</title>
      <link>https://www.xzywisdili.com/post/2023-04-26-generatewordcloudin5minutes/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-04-26-generatewordcloudin5minutes/</guid>
      <description>群里有人问，想要做一张这样的指定形状的词云：
我试了一下，其实很简单，基本上 5 分钟就搞定。这里的简单思路就是：
使用 jieba 包对原始文本进行分词处理; 将分词之后的结果导入 wordcloud 包生成分词。 至于指定形状的需求，需要注意在 WordCloud() 中的 mask 参数导入指定的形状遮罩图片就好，具体的代码如下：
import jieba from wordcloud import WordCloud import numpy as np import PIL.Image as image # 对分析文本做分词处理 def cut(text): word_list = jieba.cut(text) result = &amp;#34; &amp;#34;.join(word_list) return result # 读取分析文本，进行分词 with open(&amp;#34;D:\\测试文章.txt&amp;#34;, &amp;#39;rb&amp;#39;) as fp: text = fp.read().decode(&amp;#39;utf-8&amp;#39;) words = cut(text) # 设置目标词云的遮罩 mask = np.array(image.open(&amp;#34;D:\\测试图片.png&amp;#34;)) # 进行词云分析并生成 test_cloud = WordCloud( mask = mask, background_color = &amp;#39;#FFFFFF&amp;#39;, font_path=&amp;#39;C:\\Windows\\Fonts\\方正聚珍新仿.</description>
    </item>
    
    <item>
      <title>数据挖掘的奇效——爬到网站没有显示的数据</title>
      <link>https://www.xzywisdili.com/post/2023-04-23-userjsonfindextradata/</link>
      <pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-04-23-userjsonfindextradata/</guid>
      <description>有没有想过，有些网站的页面上展示的数据只有一部分的时候，通过稍微一点挖掘就能发现额外的数据，收获更多信息。
这里就举一个最近发现的例子——云顶之弈公开赛“云巅赛道”的官方实时排名更新。 可以看到，这里只展示了云巅赛道前 60 名的用户昵称、段位、胜点、排位场数、登顶率和前四率。
但是其实，只要扒到网站请求的数据，兴许可以看到更多的数据。
发现网站请求返回的数据 这里其实没有想象中那么难。在「检查」中的「网络」选项卡查看网站的请求，一眼就能发现这个全是大写的请求返回的 json 数据。 稍微看一下，各类数据也都对的上，就是这个了：
这里可以复制请求链接，再每隔一段时间请求一次，查看实时更新变化，我这里就不做了，有兴趣的可以查看我的另一篇文章。我就直接将 json 数据保存到了本地。
使用 RJson 解析 json 格式数据 这里就使用一下 R 语言中的 RJson 包来解析一下 json 格式数据：
library(rjson) result &amp;lt;- fromJSON(file=&amp;#34;云巅.json&amp;#34;) result 可以看到，直接使用 fromJSON 读取出来的是 list 格式的数据，还是多次嵌套的 list：
第一层：每一个用户作为一层; 第二层：单个用户下的每一个变量数据作为第二层； 同时，可以看到，最关键的用户名 sName 变量用了 URL Code 编码，需要再使用 URLdecode 解一下。
这就需要先进行多层 list 数据的解包，加上稍微一点预处理了：
library(tidyverse) # 将 json 数据的每一层（每一个用户）转换成单行数据 row_results &amp;lt;- lapply(result[[2]], function(x) { as_tibble(x) }) # 对单行数据进行合并，得到最终数据 toc_rank_result &amp;lt;- do.call(&amp;#34;rbind&amp;#34;, row_results) # 使用 URLdecode 转换用户昵称 toc_rank_result &amp;lt;- toc_rank_result %&amp;gt;% mutate(nickname = URLdecode(sName)) %&amp;gt;% select(nickname, iTier, iRank, iPoints) # 查看转换后的数据 View(toc_rank_result) 大功告成！可以看到，相比于官网页面上的 60 条数据，这里分析的请求数据总共有 100 条，足足多了 40 条。 而且爬下来的数据想要做更多的查询和分析也更加方便了。 有时候，网页上没有显示的数据，可能还真需要扩展一下思路，看看能不能用其他方法得到。</description>
    </item>
    
    <item>
      <title>【学习笔记】实用统计学复习手册01——探索性数据分析</title>
      <link>https://www.xzywisdili.com/post/2023-03-23-dataanalysisnote01/</link>
      <pubDate>Thu, 23 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-03-23-dataanalysisnote01/</guid>
      <description>总结 介绍了数据的分类（数值型、分类型）等； 单变量分析：位置度量（均值、中位数）、变异性度量（方差、标准差、百分位数）等； 单变量的可视化：箱线图、频数表、直方图等； 多变量分析：探索相关性。 多变量的可视化：散点图、热力图、列联表、分类箱线图等； 探索性数据分析（Exploratory Data Analysis，EDA）是数据科学项目的第一步。
数据的分类和主要形式 首先，需要了解数据的分类。在目前世界，数据来源非常丰富，而大多数数据是非结构化的，比如图像、文本、用户交互。这些“信息”，或者说非结构化的数据必须先转化为结构化的数据，才能够用于下一步的分析。
结构化数据的分类：
数值型数据 离散型数据：只能取整数； 连续型数据：在一个区间可以取任意值 分类型数据 二元数据：两个值中取其一，0 或 1 多元数据 特殊形式：有序数据，按照分类进行排序 需要强调的是，数据的分类对于后续可视化方法的选择、统计模型的选择都非常重要。
接下来需要说明的是数据科学中最经典的引用结构——矩形数据。最常见的就是我们经典的电子表格。其中每一行代表一条观测记录，每一列代表一个特征（变量）。在不同统计编程语言中也有对应的处理方式：
R语言: data.table Python Pandas: DataFrame 其他的几种非矩形的数据形式包括：时间序列数据、空间数据和图形或网络数据。他们都有对应的处理方法。
如何描述连续性变量？ 位置度量 变量代表了测量数据或者计数数据。探索数据的一个基本步骤，就是了解每个变量（特征）的特点。不同种类的数据，我们对其的主要关注点也不尽相同。统计学中主要关注以下数据特征值：
均值：基本的位置度量，对极值敏感 加权均值：将每个值乘一个权重值然后除以总和 切尾均值：消除极值之后的均值，比均值更加稳健 中位数：更加稳健，不易受均值影响 加权中位数：将数据集排序之后进行加权，加权中位数就是可以使数据集上下两部分的权重总和相同的值 离群值：并不一定是无效或错误的数据，但往往是由于数据的错误所导致的。 统计学家替换用估计量（estimate）来表示从手头已有数据计算得到的值，来描述数据情况与真实状态之间的差异。数据科学家和商业分析师更倾向于把这些值称为度量（metric）。因为统计学的核心在于如何解释不确定度，而数据科学则更关注如何解决一个具体的商业或企业目标。
变异性度量 变异性（variability），也称为离差（dispersion），是另外一个描述数据的视角，表示数据是紧密聚集的还是发散的。在分析中主要会考虑：
测量数据的变异性； 识别各种变异性的来源； 如何降低变异性 统计学中有以下数据特征描述变异性：
偏差：观测值和估计值之间的直接差异 方差 标准差：方差的平方根 平均绝对偏差：对偏差值取绝对值然后求平均 中位数绝对偏差 极差：最大值和最小值之间的差值 顺序统计量：又称为秩 百分位数 四分位距（IQR）：75 百分位数和 25 百分位数之间的差值 方差和标准偏差是最广泛使用的变异统计量，且都对离群值敏感。更稳健的度量包括百分位数、四分位距和中位数绝对偏差。
sd (state$Population) IQR(state$Population) mad (state$Population) quantile(state$Murder.Rate, p=c(.05, .25, .5, .75, .95)) 使用图表描述数据分布 箱线图 boxplot(state$Population/1000000, ylab=&amp;#34;Population (millions)&amp;#34;) 箱线图的顶部和底部分别是 75 百分位数和 25 百分位数。水平线代表的是中位数，虚线称为须（whisker） ，从最大值一直延伸到最小值，体现了数据的极差。</description>
    </item>
    
    <item>
      <title>【学习笔记】保序回归——适用于单调递增数据的统计回归方法</title>
      <link>https://www.xzywisdili.com/post/2023-03-07-isotonicregression/</link>
      <pubDate>Tue, 07 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-03-07-isotonicregression/</guid>
      <description>什么是保序回归？ 保序回归（Isotonic Regression）是一种适用于单调函数非参数统计回归方法，即在一个序列中，Xn ≥ Xn-1。通过字面理解「Isotonic Regression」：
iso的意思就是「相等、相同」的意思； tonic 就是 tone 的意思，指的是「调」。 所以保序回归的核心还是在于单调递增的函数，当需要分析的数据资料符合单调递增的趋势可以用。 保序回归最常用的应用场景之一是探索药量和药效的关系，因为一般来说药物剂量越高，药效应该更强，因此通过保序回归的方式可以从药效和经济学的角度估计最合适的药量。
保序回归使用 weighted least-squares 来进行拟合： 怎么做保序回归？ 求解保序回归的一种最常用算法是 PAVA 算法（ Pool-Adjacent-Violators Algorithm，池相邻违规者算法）。PAVA 算法的直观形式只需要看下面这张图就行了：
这种算法是通过从左往右逐渐扫描数据序列，并且保证整个序列是单调递增的，以此来获得 Beta 值的结果。如果 Beta_i &amp;lt; Beta_i-1，那么就同时把这两个值替换为 (Beta_i + Beta_i-1) / 2。以此就能获得严格且平滑的保序回归。
通过 PAVA 算法，可以获得一个包括多个 Beta 参数组成的单调递增序列，用可视化的方法可以看到是由多条上升线和水平线组成的函数图：
如何使用 R 语言进行保序回归？ 在 R 中可以轻松进行保序回归，只需要使用 stats 包中的 isoreg 函数即可。下面的代码提供一个简单的示例，并将原始数据和拟合值（蓝点）绘制出来。注意，拟合后的蓝点是单调递增的。
# Generate Training Data set.seed(15) x &amp;lt;- sample(2 * 1:15) y &amp;lt;- 0.5 * x + rnorm(length(x)) # Isotonic Regression Model Fit reg.</description>
    </item>
    
    <item>
      <title>【把书读薄07】《所罗门的密码》：试图分析人工智能的信任问题却深度不足</title>
      <link>https://www.xzywisdili.com/post/2023-03-03-bookreview07/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-03-03-bookreview07/</guid>
      <description>总结 《所罗门的密码》总结了人工智能在方方面面改变整个社会的同时，可能出现的问题和挑战，并倡议出版一份《全球人工智能经济大宪章》。 书中大篇内容均是过去材料的堆叠和老生常谈的问题陈述，没有作者自己深刻的思考，和独到的见解； 评分：2.5/5.0； 推荐受众：无，不推荐任何人阅读。 作者借用了所罗门的故事，想要寓言人类社会不善用人工智能的未来。[所罗门王](所羅門 - 維基百科，自由的百科全書 (wikipedia.org))是《圣经》中的一个人物，代表着智慧。他最出名的一个故事就是“所罗门的审判”。 但拥有智慧的他误入歧途，让他建立和统治的王国深陷衰落和动荡。天才的智慧得到了浪费，并为此付出了沉痛的代价。
但我认为，单纯地用这个例子去比喻人工智能，也不是那么恰当。
从人工智能的本质去理解信任问题 目前来看，人工智能的本质，即收集数据，分析数据，构建模型。一般而言，想要得到更好的模型，需要海量，且高质量的数据。最近火爆的 ChatGPT 更是证明了这一点：当数据量足够大，同时模型参数足够多的情况下，人工智能模型能够展现出无比强大的通用语言能力。
但是，这里就引出来问题的关键：谁能同时拥有高质量的海量数据，又拥有能够驾驭这些数据的分析团队？
那就是数字行业的巨头公司，比如脸书、谷歌和阿里巴巴等。
那么，关于对人工智能的信任问题，其实就是广大用户和数字巨头之间的信任问题了。
在数字巨头提供 AI 服务，和大众用户供养数据的过程中，不可避免会产生关于以下的信任问题：
准确性与责任：广告推送可能无需很高的准确性，但医疗、无人驾驶等需要极高的准确性要求； 信息收集和滥用问题； 价值观：AI 模型的利益取向、价值观等； 其他问题 而在此过程中，由于数字巨头一开始便拥有垄断优势，在常年累月的数据积累和模型迭代后，垄断的趋势会更加强烈。这就导致对于大众用户来说，想要像选择超市商品一样更换品牌，是非常之困难的。
这就对数字巨头有着相当高的要求了：不能为了自身利益损害用户权益，不能滥用用户信息和数据，时刻对模型和算法进行监督和自查，在出现问题时承担起应有的责任……而以上的每一项对于一个商业公司来说都是巨大的显性或隐性的成本负担。
那么如何进行约束？ 这就是问题真正的困难点所在。一般而言，大家能想到的是以下两种方式，不过这两种方式都有显而易见的困难点。
通过政府或第三方对算法和模型进行监督和审核。 但是，要清楚的是，目前主流的人工智能模型，如深度神经网络，其结果的输出是「在混沌中涌现出来」的。即使是算法工程师本身，面对这个黑箱，或者炼丹炉，都无法 100% 完全参透其中的作用机制。那么也实在难以确保其中的公开透明，或者公正和准确。而且，不可否认的是，监督本身也会对人工智能的创新产生或多或少的遏制作用。
只允许人工智能给人类提供建议，真正的决策权还是把握在人类手中。 听起来很美好，但仔细想想，人类自己的认知和心智是否足够强大到，可以理性地看待 AI 的建议而不受其影响。这样是否也会隐性地左右人类的价值观和所谓的选择权？又或者这也是一种逃避责任的方式罢了？
无论如何，人工智能都已经在逐步对整个社会进行改造和重塑。但数据并非万能全面，至少价值观念、人类情感等等属性还暂时难以完美地量化。在此基础上，我们需要找到人类和人工智能的相处方式，让 AI 能够良性地辅助我们的工作和生活，而非吞噬。</description>
    </item>
    
    <item>
      <title>【把书读薄06】Excel 学习真的不适合借助书本了</title>
      <link>https://www.xzywisdili.com/post/2023-01-30-bookreview06/</link>
      <pubDate>Mon, 30 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2023-01-30-bookreview06/</guid>
      <description>总结 《跟李锐学Excel数据分析》 名为「数据分析」，内容实则是 Excel 软件使用技巧，这点需要读者注意； 虽然页数看起来较多，但是大量篇幅均为各种实操步骤截图，伴随每一个步骤讲解，友好度不如视频； 评分：2.0/5.0，更建议想要学习 Excel 工具的读者去寻找视频教程；想学习数据分析相关内容的读者就更不用看了。 最近读完了《跟李锐学Excel数据分析》。可惜的是，书名有点误导性质，全书和「数据分析」关系不大，更多是介绍 Excel 的使用方式和进阶技巧。但多多少少还是跟着看完了全书，并且把对自己有点用的部分记录了下来，权当给自己复习巩固。
书中讲解的 Excel 相关知识，可以归纳为以下几点：
需要知道的进阶知识 函数和公式 实用技巧和快捷键 更多高级用法：数据透视表、Power Query、Power Pivot 在这些内容中，最常用的需要非常熟悉。而相对不那么常用的，只要知道其存在，脑子里有个印象即可。具体用法细节可以在用的时候，稍加检索，基本上也可以了。
一、需要知道的进阶知识 这里有几个需要优先了解的进阶知识，方便在后面的公式部分进行组合，发挥出更强大的威力。
绝对引用，相对引用，混合引用 通过在行和列号前面的 $ 符号进行控制，可以将 $ 理解为锚定，锚定住的行或列号是不会改变的。比如 $A$1:$B$8 就是一个绝对引用的区域，在自动填充中不会变化。
字符串连接符号 &amp;amp; 符号，代表字符串的连接。比如 =&amp;quot;联想&amp;quot;&amp;amp;&amp;quot;笔记本&amp;quot;，显示结果就会是 联想笔记本。
通配符 通配符，就是这个符号能匹配多种字符，在查找和替换里经常会用到，以下几种最常用：
问号 ?：占位一个字符； 星号 *：占位多个字符； 波浪号 ~：右侧的符号为普通字符，比如 ~* 指代的就是星号。 跨表符号 一般在需要跨表引用的时候，使用 ! 进行连接，比如 sheet1!$B$4:$F$8 代表引用 sheet1 的 B4 到 F8 范围。
二、快捷键 说到快捷键，其实最推荐的学习方式就是在某宝上购买一个快捷键桌垫，在手边经常能看到，日积月累耳濡目染也能记得不少，可以反复加深印象：
不过还是总结了书里提到的几个常用的快捷键：
&amp;lt;Alt + =&amp;gt;：行和列的求和汇总； &amp;lt;Ctrl + Enter&amp;gt;：批量填充，非常好用； &amp;lt;Ctrl + E&amp;gt;：自动填充，可以批量提取和合并数据，甚至部分场景可以智能合并数据； &amp;lt;Ctrl + T&amp;gt;：快速在现有表上创建表格； &amp;lt;Ctrl + 1&amp;gt;：设置单元格格式； &amp;lt;Ctrl + Shift + 数字&amp;gt;：快速切换单元格格式（常规、文本、日期、货币、百分比等等）； &amp;lt; F5 &amp;gt;：定位 三、公式 有一些非常经典好用的公式，是需要记住使用方法的。而我认为，其他公式，只需要脑子里有个印象即可，当需要用到的时候，在网上稍微查一下用法和各个参数就行了。这里列举一些比较常用和好用的公式。</description>
    </item>
    
    <item>
      <title>（2022年11月过）SAS Advance 考试最新完全攻略！</title>
      <link>https://www.xzywisdili.com/post/2022-11-08-sasadvance/</link>
      <pubDate>Tue, 08 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2022-11-08-sasadvance/</guid>
      <description>今天终于通过了 SAS Advance 的考试。有一些最新的备考和考试过程的经验可以跟大家分享一下。 这篇攻略我会从两个方面来说，分别是备考篇和考试篇。
备考篇 SAS Advance 的考试并不难，主要是考察三个部分：Proc SQL 语句，SAS 中Macro宏的应用以及一些进阶编程技巧。 只要用我下面列出的备考材料复习，就完全不用担心过不了。所有材料的分享链接在最后。
官方教材《SAS Certified Professional Prep Guide: Advanced Programming Using SAS 9.4》 注意，一定一定不要用老版的教材，老版的教材有 800 多页，看完太费时间，而且还有大部分内容不会考察，还有部分要考察的内容没有涉及。所以一定要认准总共 400 余页的新版教材。另外，可能在某亩三分地或者其他论坛里分享的教材版本是乱码的，里面的代码片段和图片也有很多缺失。我找到了完整的电子版书籍，内容是完整的，分享链接也在下面。
论坛大神 Mike Q 总结的 20 道 Lab 试题 Lab 试题，即需要你在考场上实机编写代码进行解答，具体情况是：
左侧显示题目信息和要求； 右侧是一个远程编程环境窗口，供你写代码使用； 备考时候可以提前看一下 SAS 官方提供的讲解视频，熟悉操作； 实机操作的题目不用担心，不会很难，题型基本上都涵盖在了上面的 20 道 Lab 机经中，考前一定要至少刷一遍！最好自己亲手敲一遍代码，更加熟悉。
论坛大神总结 63+20 题 这部分主要针对的是考试中出现的选择题，63+20 题版本已经可以涵盖绝大部分的考试范围了。我分享的版本除了题目，还有详细的题目答案解析，总共内容不到 100 页，考前至少刷一遍就好。另外需要注意，正式考试中还覆盖了正则表达式（Perl Regular Expression）的题目，在刷题之余还需要翻看一下教材。
备考总结 总结一下怎么备考：
有富余时间建议过一遍教材（包括课后习题），没有时间的话可以跳过直接刷题； 一定过一遍 Lab 20 题，至少亲手敲一遍代码； 一定过一遍 63+20 题，可以看答案过一遍之后，挡住答案自己做一遍。 考试篇 考试篇我会分为线上考试和线下考试分别讲讲是怎么样的（对，我很悲催地两种都经历过）。
无论是线上还是线下都可以在官网进行报名；按照步骤注册登录，然后选择自己想要参加的考试（本文中是 SAS Advance Programming - Performance Based）就行了。之后在选择考试方式（线下 or 线下），预约时间，进行付费就可以了。付费需要使用海外信用卡支付 180 美元。</description>
    </item>
    
    <item>
      <title>【把书读薄05】向心城市：带你了解现代城市的发展规律</title>
      <link>https://www.xzywisdili.com/post/2022-10-19-bookreview05/</link>
      <pubDate>Wed, 19 Oct 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2022-10-19-bookreview05/</guid>
      <description>总结 《向心城市》中作者通过大量的数据分析实证，介绍了城市的发展规律、为什么“向心城市”是发展趋势，以及城市化带来的各种方面的内容分析； 评分：3.8/5.0，书中的大量内容更加面向城市的规划者，感兴趣的可以细读；至于想要在书中找到未来人生的抉择，其实可以跳读，内容不算太多。 城市的本质是什么？城市的未来会怎么发展？《向心城市》中通过对大城市的各种数据的实证分析，为我们揭示了城市的发展规律。
城市越来越大是未来的趋势 为什么会出现城市？为什么在经济发展的过程中，出现了一个又一个的大城市？
作者告诉我们，这是经济发展的客观规律。城市本身出现和长大的过程，其实是为了方便人与人的见面。无论是投资、生产还是消费行为，都极度依赖人与人的见面沟通。
而且，你会发现，越方便人与人见面的地方，比如市中心，根据市场的竞租机制，一般都会留给金融业；而次靠近市中心的地区，则是科技型企业和教育行业；而外围则一般是制造业的企业。住宿用地则夹在制造业用地和市中心中间的部分。这便是城市的基本构成，也是天然形成的最优化的结果。
这样来看，白天，人口集中在靠近城市中心的地段进行工作；而到了夜晚，则向外扩散回到居住地，即内环和内外环中间的地区。
那为什么城市越来越大，即“向心城市”才是未来的趋势呢？
作者认为，在现有发展阶段，农业和工业趋向发展到了一定阶段，其实很大一部分的经济动力来源于新增的服务业。服务业也会带来大量的营收和新增就业岗位。这样一来，很多小城市或者农村的人员就会进城，得到收入更高的工作。这样就形成了一个循环：
城市有更多的人口，能够产生更丰富的需求和消费行为，供养更丰富的服务业； 更丰富的服务业同时带来了更多收入更好的岗位，吸引人口流入。 如此一来，大城市就会越长越大，人口也会从小城市慢慢向大城市集中。这个趋势已经在中国和众多国家实现和发生，未来也将持续。
大城市越来越大的问题怎么办？ 那就有很多人表示，大城市的人口越来越多，那所造成的拥堵和污染问题怎么解决呢？
这一点，作者也列举出了数据来回答：那不是人口的锅。
比如，作者认为人口较多的大城市与小城市相比，拥堵指数的 1.8 和 1.6 相差并不大。而北京、济南和哈尔滨则作为离群值，拥堵的根源主要在于交通规划和治理水平不到位。而从另一个角度想，人口密度更高的地区，居住场所周围的商业中心、交通站点和医疗中心的平均距离和时间也变短了。换句话说，人们的生活圈半径也缩小了。
所以，人口越多的大城市的拥堵会略微增大，但是还是在可接受范围内。
而对于污染，作者通过控制一系列经济发展变量，认为“城市市区人口与八类污染排放量均不再相关”。
这里我觉得太过于武断了，首先，人口规模和一系列变量（比如经济变量）一定存在多重共线性的问题，这里面的混杂因素是否考虑进去了；其次，决定系数（R^2）小于 0.8 就认为不再相关也在统计学上比较具有争议；另外，作者认为“斜率（系数）均小于 1代表污染排放的增速远小于人口增速”就更匪夷所思了。人口规模和污染排放的单位必然不同，其次用线性模型时已经假设了人口规模和污染排放呈现线性关系，又怎么再用拟合之后的结果去反过来推断人口在大城市和小城市的贡献率高低呢？
那这样是不是对人口流出地区不太公平？ 当然，那有人会觉得这对于人口流出地区太不公平，人口越来越少，可能经济凋敝，没有发展空间……
作者认为流出地区还是应该顺应经济发展的规律，既然人口在流出，就要谨慎规划自己的建设。不要随意地建设新城和各种大面积的住宅和金融中心。相反，应该找到本地区的特色产业。发展有时候不一定等同于「经济总量」，如果把思路转变成「发展」和「平衡」意味人均 GDP 的均等化，或许更为合理。
人口的流动，其实也是一种「用脚投票」。既然当地已经无法大幅拉高 GDP，那人口的减少其实也是变相增加了人均 GDP。而让大城市和小城市在某种程度上，在流动中走向了平衡。同时，从总体上来看，人均收入也在逐步获得提高。
比如广东，广州和深圳 GDP 总量增长非常快，同时人口也在向这两个城市集中；而其他城市 GDP 虽然增加较慢，但是人口减少，这样人均 GDP 也在上升。通过人均 GDP 的比较发现，人均 GDP 的差距是有缩小的趋势。
最大的收获是用数据找规律 读完本书，除了真的部分了解了城市发展的规律之外，其实最大的收获是收集数据来发现规律的做法。
可能很多人觉得这没有什么新奇的，但是在互联网上有太多信口胡说的财经或者经济博主，单纯凭自己的个人体验和主观臆断，就能“胡扯”出很多完全靠不住脚的结论。这也让遵从数据事实认真分析的内容变得更加可贵。
比如，作者在书中通过收集早晨和夜晚的通信数据来反映早晚城市人口迁移情况；通过货车运输轨迹密度图反映中国城市群的情况；通过第三产业产值、城市夜间灯光与其他国家进行对比来反映我国城市的发展进程情况……
在数据中发现规律，或者验证理论，我觉得这是我阅读本书的最大收获之一。</description>
    </item>
    
    <item>
      <title>【把书读薄04】一日两餐：找回身体代谢灵活性的新饮食理念</title>
      <link>https://www.xzywisdili.com/post/2022-09-26-bookreview04/</link>
      <pubDate>Mon, 26 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2022-09-26-bookreview04/</guid>
      <description>总结 《一日两餐》想让我们通过限制碳水摄入和间歇性禁食这两个重要手段来摆脱未来的胰岛素抵抗； 书中的大量内容更像是别处观点的拼凑，同时时不时夹杂一些带货着实会令读者不悦； 评分：2.5/5.0，仅摘取前半部分的关键阅读即可，后半部分实在不推荐。 现代饮食理论提出的新观点认为，每日三餐的高碳水化合物的摄入，外加各种精制加工食品才是损害我们健康的元凶。《一日两餐》的作者想要为我们讲解这背后的理论原理「高胰岛素血症」，以及我们为什么需要「限制碳水」和「间歇性禁食」来帮助我们减掉身体多余的脂肪，降低糖尿病、心脏病的发生概率，获得一个健康、快乐和精力充沛的生活。
现代人类正在面临胰岛素抵抗的危机 胰岛素是胰腺分泌的一种代谢激素。在正常情况下，人体摄入的碳水化合物会转化为葡萄糖，这些糖少部分会直接消耗，绝大多数则会听从胰岛素的安排，从血液去往目的地。其中一部分会去肌肉或肝脏转化为糖原储存，另一部分则去往脂肪细胞转化为甘油三酯。
现代的食品工业和饮食让人们疯狂地摄入碳水化合物，导致胰岛素得持续地维持工作，来处理血糖的负担。而长时间地持续分泌胰岛素，会最终导致细胞上的受体对胰岛素不再敏感，这也就进入了胰岛素抵抗的状态。很多人也把这种状态称作代谢综合征，会带来一些显著的健康问题：高血压、高血糖、高血脂和腹部脂肪多。同时，还会导致氧化应激、慢性炎症和糖化，而这些被医学界认为是心血管疾病、癌症和衰老的关键驱动因素。
作者认为，当我们深陷“血糖-胰岛素过山车”的模式中，就会丢掉我们相当重要的一个能力——「代谢灵活性」，即可以根据身体的需要去燃烧各种能量来源的能力，尤其是储存的脂肪。拥有这种能力则让我们整日体感良好，后续的各种健康风险也会大大降低。
因此，简单地说，我们要避免胰岛素抵抗，重新获得代谢灵活性。
怎么重获代谢灵活性？ 现在，为了达成避免胰岛素抵抗，重获代谢灵活性的目标，我们当然需要改变日常饮食习惯。但是！可以忘掉计算热量等等的麻烦事，我们只需要关注以下几条：
避免缺乏营养的精加工食品（尤其是含糖饮料和精制碳水）； 减少进食，开始间歇性禁食； 第一步：从饮食中剔除现代的有害食品 作者认为，现代三大有害食品是添加糖、精制谷物和精炼种子油。这些碳水不仅缺乏营养，同时还大量刺激体内胰岛素分泌，诱导进入胰岛素抵抗的状态。
但可惜的是，我们现在的饮食文化中这些已经随处可见。米、面、饼等等已经成为绝大多数人家的主食必备，而商店的饮料货架上的绝大多数都是含糖或者代糖饮料，同时各种的甜品和零食也在刺激和引诱我们的食欲。想要完全摆脱这些真的有点难。
但我们需要好好反思一下这“三巨头”所带给我们的：
精制谷物：大量的、纯粹的碳水不仅缺乏营养，还增加了我们对糖类的代谢负担，分泌过量胰岛素的危害逐渐浮现； 加工糖和代糖：额外添加，只为满足口舌之欲，实质上摄入体内也在增加代谢负担，让胰岛素过量工作； 精制种子油：非天然的化学组成，通过与天然脂肪分子相似的特性蒙骗了身体，整合进了脂肪细胞中，导致脂肪很难作为燃料燃烧，阻碍了代谢灵活性； 那我们应该多吃什么呢？作者认为我们应该重视以下这些营养密度更高的食物：
肉、鱼、禽、蛋、海洋生物、动物肝脏、带骨肉、骨头汤 蔬菜：含有抗氧化剂、类黄酮、类胡萝卜素等植物营养素、维生素； 新鲜的应季浆果 坚果：含有蛋白质、脂肪酸、抗氧化剂、维生素及矿物质等； 天然乳制品：避开加工的含糖酸奶、风味酸奶等等； 黑巧克力：富含抗氧化剂和矿物质，尽量选择可可含量至少 70% 的产品，避开牛奶巧克力或半糖巧克力这些糖分炸弹 饮料：水、不加糖的茶和咖啡 以谷物为基础的饮食体系实质上是食品工业推销风行的一种不好的饮食习惯。
麸质和谷物中的反营养物质，作者认为日常司空见惯的嗳气、腹胀、便秘、短暂性腹痛和偶尔性腹泻其实都是身体对这些“非营养物质”中的毒素的不良反应。
精炼种子油、精制谷物和精制糖
通过日常禁食、规避精制碳水化合物和种子油这样的生活方式行为，来降低膳食导致的胰岛素产生，从而向你的基因发出“燃烧脂肪”而非“储存脂肪”的信号。当你成功降低胰岛素时，你就能将储存的身体脂肪作为首选的能量来源，而不是将你摄入的热量当作首选，进而燃烧脂肪。
第二步：开始间歇性禁食 间歇性禁食是一个比较新的进食理念，即我们人类其实无需早、中、晚三顿饭，甚至期间不停吃零食来满足全天能量。因此，我们可以空出一段完整的时间来减轻身体的消化负担，来让身体有选择地燃烧脂肪，获得代谢灵活性。
最自然的方式，就是等到饥饿感自然到来的时候才进行进食。通过尽可能长的时间，身体能够产生抗氧化剂（比如谷胱甘肽），同时对优化内部解毒过程，让大脑和身体燃烧脂肪和酮类物质，促进线粒体的功能，同时促进线粒体的合成和效率，可以说，从代谢、免疫和认知功能都有一定的好处。
更加推荐的初步间歇性禁食方式就是 16-8 禁食法，即每天在 8 小时的进食窗口完成所有食物摄入，然后在剩下的 16 个小时保持禁食状态。比如我就准备通过稍晚的早餐和午餐在 9：00-17：00 完成进食，剩下的时间则留给禁食状态。
除此之外，在执行过程中还要注意：
关注身体的饥饿和饱腹的信号，能够更好地筹划自己的饮食进程； 推迟第一顿饭的时间，直到饥饿的时候在再吃，不必拘泥于早餐的理念； 尽量少吃零食，吃零食会阻碍脂肪燃烧，增加胰岛素的波动，还会增加每日的总热量摄入； 在到达自己的消化窗口时间可以刷牙，让口腔保持清爽，不再受到食物的诱惑； 作者时时告诉我们，只要坚持这样的饮食方式 21 天，就会有明显的健康收获。我也打算开始践行作者提倡的方式，同时使用日志记录执行情况和感受，1个月后在此分享一下，间歇性禁食到底如何。
最后，聊一下为什么不推荐这本书 虽然作者想要传递一些新鲜的饮食理念，但是书中的一些部分实在令人不悦：
拼凑内容：书中使用了相当多的篇幅来讲解需要配套的运动、睡眠、习惯养成法，甚至冷暴露等等的健康生活方式，但是基本都是东拉西拽，从别人那里拿来的，比如小A的《A书》里讲了什么什么，小B的《B书》又说了什么什么，既然没有自己的东西，也就不用强行塞到书中充数； 强行带货：你会读到在讲解酒类的部分开始推荐 XX 牌的红酒，到了睡眠部分又在推荐 XX 牌的床垫，又让读者去油管检索 XX 教练的运动视频……这些内容的出现无疑降低了科普的说服力度。 这大概也是造成豆瓣评分偏低，短评不满的部分原因。因此，大可不必阅读此书，文中的相关理念也可以通过其他渠道继续深入了解。</description>
    </item>
    
    <item>
      <title>【把书读薄03】锻炼：丹尼尔·利伯曼教授对健康迷思的一一解答</title>
      <link>https://www.xzywisdili.com/post/2022-9-21-bookreview03/</link>
      <pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2022-9-21-bookreview03/</guid>
      <description>总结 《锻炼》通过人类进化学和现代医学研究两方面，对广泛流传的各种健康迷思进行了验证和解释； 关于久坐、睡眠、运动损伤、运动与衰老等等话题，你一定能看到种种新奇的视角和极具说服力的验证； 评分：4.8/5.0，非常难得的健康科普阅读体验，部分章节之后会重新翻看。 社会上流传了许多健康迷思：「久坐会带来健康风险」、「每晚睡眠达到8小时才是最佳状态」、「仅靠步行，无法减肥」等等内容。我们有时候接受了这些理论，仅仅是因为很多人（包括专家）都这么讲，但却从来没有思考这些说法究竟有没有道理、原理是什么。而丹尼尔·利伯曼想用《锻炼》这本书尽量把这些健康迷思讲清楚。身为哈佛大学的进化生物学教授，他带来了进化生物学的视角，从人类的进化讲起，到现代医学研究阐释的原理。看完这本书，我是真的感觉自己打开了眼界，又被里面的原理和验证所说服。
避免非必要的身体活动才是进化的结果 首先有一个最基本的观点（当然可能各位已经在生物课上学习过），即「人体在静息状态下依然在消耗能量。」更重要的是，这部分能量并不低，静息代谢消耗的能量要占据每日总热量消耗的 60% 到 75% 之多。
静息状态的能量消耗主要来自于各个器官的辛勤工作。比如心脏在不停收缩、泵血当然需要能量；肠胃在消化，肝肾在调控和过滤血液当然需要能量；大脑在思考，更需要能量……静息状态，虽然我们看上去什么都没有做，但是各种维持生命的生理活动一直在进行，并且消耗能量。
而在进化过程中，人体也学会了怎么分配能量。在从类人猿进化到人类的过程中，我们深知能量的重要性（当然，没能量就会嗝屁）。而在能量有限的情况下，分配的优先级就很重要了。而人体实际上可以把能量花在以下5个方面：身体成长、生命维持（静息代谢）、能量存储（例如，以脂肪形式存储）、运动、繁衍。
在进化生物学的理论中，「生命维持」和「繁衍」是这五项里最最优先的两项，这也符合我们的认知：没了生命维持就嗝屁了，而繁衍是刻在基因里的种族任务……所以，其实作者想表达的结论就是：
「避免非必要的身体活动，才是进化的结果。」
换句话就是，「我们生而懒惰」。当然，在这个语境下，「懒惰」已经不是一个贬义词了，更象征着人类在漫漫进化长河中的一种实用的适应。
那么问题来了，既然所谓的「懒惰」是人类的正常选择，而「久坐非常不利于健康」的说法也流行已久了，这两个观点又该如何理解呢？
久坐是怎么带来健康风险的 其实关于久坐有两个已经公认的事实：
现代人每天久坐的时长要比过去更长。 统计显示现代人平均每天坐的时长占非睡眠时间的 55%-75%，即 9-13 个小时； 站姿或者其他活动要比坐姿消耗更多的能量。 很好理解，因为牵涉到肌肉的伸缩和协调。 这样一来，久坐和健康风险的关系链就呼之欲出了。久坐让“运动”这一部分的能量节省了下来，而能量不会凭空消失，就会存储成为脂肪的形式；脂肪细胞的膨胀招致了白细胞前来并向血液释放了大量炎症细胞因子，形成了慢性轻度炎症。简单一句话总结：久坐会让你变胖，而变胖会带来健康风险。
现在的问题是，怎么解决这样的健康风险？研究告诉我们，只要保持了久坐的习惯，哪怕你坚持在下班时间进行锻炼，也依然于事无补，这部分健康风险是无法抵消的。所以只剩下了两个选择：
间断性起身做轻量运动； 折中的方法：“不安分” 地坐着 这里的原理在于，保持这种“不安分”的活动会让肌肉保持收缩，然后燃烧掉血液中糖和脂肪的能量；另外，肌肉受到的刺激，能够带动抗炎反应，消除体内的炎症。
当然，这只是开胃菜，后续精彩纷呈 久坐只是作者论述的第一个话题，而从此篇也逐渐渐入佳境。在接下来，作者对于「8小时睡眠理论」、「步行减肥理论」、「奔跑的速度与耐力」、「锻炼如何延缓衰老」等等话题一一进行了讲述。而且你能明显地感觉到，每一个话题都并非泛泛而谈，而是经过了作者深入的思考。
让我印象最深，也最有趣的例子，莫过于「体育与人类自我驯化」。
体育其实是人类自我驯化的产物 这里先要理解两个概念：「应激性攻击」和「主动性攻击」
高应激性攻击：你只要惹我，我不过脑子立马就干你，行为不受控制； 低主动性攻击：完全由大脑主导和控制，通过策划行动、互相协作、谋求时机来进行攻击。 在还未完全进化的类人猿形态，其实就是高应激性攻击和低主动性攻击。但是进化过程中，拥有团队协作能力进行捕猎的人类和受到异性青睐的人类逐渐在自然选择中赢得胜利，慢慢地变成了低应激性攻击和高主动性攻击。
这个过程其实和野狗驯化成家狗的过程有一定相似性，换句话说，就是「人类的自我驯化」。
而早期的体育活动，很大程度上其实就是人类在训练自己的狩猎技巧、生存技巧和团队协作能力，这样又能使种族更好地生存和繁衍。你会发现，其实体育有一个非常关键的特征：就是对于应激性攻击行为的自我控制。绝大多数体育规则中，场上队员对对手的粗暴的应激性攻击都是违反规则的。
对锻炼有一个正确的认知 其实通读完本书的最大收获就在于，对「锻炼」这件事的理解更深刻了。
锻炼是近代诞生的产物，我们从没有进化出锻炼的本能，但是锻炼本身对我们身体是有益处的。规律性的身体活动是延缓衰老和延长寿命的最佳方式。当我们再回过头重新审视这一切，我们就不会对那些不喜欢锻炼的人进行苛责，同时喜欢锻炼的人也能明白锻炼到底给我们带来了什么。不过分夸大锻炼的功效，但也需要承认锻炼的益处，我认为这才是看待「锻炼」这件事最正确的态度了。</description>
    </item>
    
    <item>
      <title>【把书读薄02】开启高质量沟通的第1分钟</title>
      <link>https://www.xzywisdili.com/post/2022-09-05-bookreview02/</link>
      <pubDate>Mon, 05 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2022-09-05-bookreview02/</guid>
      <description>总结 《开启高质量沟通的第一分钟》目标是让职场工作沟通的双方可以通过一段简短的引言快速进入良好的沟通节奏； 书中凝练了一套沟通结构：沟通框架（背景 + 意图 + 关键信息）+ GPS 概述法（目标 + 问题 + 解决方案）； 评分：4.5/5.0，前半部分讲述框架细节非常有价值。 职场工作交流中，最希望的对话方式是简明扼要，沟通双方同时理解背景，并且谈话目的清晰。但是现实中往往出现谈话者讲了很久，聆听者却始终不明白其意图和表达主题的情况。因此，本书提炼了一个在正式交谈前的引言框架，用大约 1 分钟的时间，让职场沟通进入一个良好且高效的沟通节奏。
引言可以用两个部分讲完 书中介绍的引言可以凝练成以下的这条公式：
沟通框架（15秒，最好3句话讲完） 背景：希望讨论的主题，让对方的注意力集中； 意图：希望对方接收到你的信息之后怎么做； 关键信息：类似内容提要，凝练总结所有内容中最重要的部分。 GPS 概述法（45秒） 目标（Goal） 问题（Problem） 解决方案（Solution） 沟通框架 = 背景 + 意图 + 关键信息 这里，「沟通框架」部分需要重点拆解一下。
「背景」，目的是让对话的双方能够第一时间聚焦在同一个主题中。一般而言，内容为：要讨论的项目名称、要讨论的某个客户或订单、要讨论的某个流程环节等等，比如「我认真查看了你发送给我的开发需求文档。」
「意图」，就是直截了当地说清楚，希望对方接收到你的信息之后怎么做。一般包括：需要提供意见、需要对方决定、向对方进行汇报或告知等，比如「文档中有一些细节需要您进一步核实。」
「关键信息」，是谈话对象必须知道，最为重要的那句话，也是最重要的中心思想的概括。尽量需要凝练到简短的一句话里，比如「需求列表的排期不符合我们的工作安排。」
这样进行组合就能形成一个比较凝练的沟通框架：「我认真查看了你发送给我的开发需求文档，文档中有一些细节需要您进一步核实。里面的需求列表的排期不符合我们的工作安排。」这样，用 3 句话就能够让对话双方进入明确接下来的沟通重点。
GPS 概述法帮助沟通双方着眼于解决方案 GPS 概述法则更为简单，也更容易记忆，包括三个部分：目标（Goal）、问题（Problem）和解决方案（Solution）。
举一个简单的例子：我想要拿到对岸的旗子（目标），但是中间有一条河无法跨越（问题），认为需要建桥跨过障碍（解决方案）。
从本质上来说，几乎所有的工作沟通都是为了解决问题。所以 GPS 概述法的核心也是为了让谈话聚焦在解决方案上，无论是找到解决方案还是对现有方案进行调整或者修改。
实际应用：先分列点，再组合起来 在了解了上面讲述的沟通的各种组件之后，如果想要实际应用，可以先把每个组件罗列出来，然后再组合成沟通的引言。举一个书中提到的实际例子：
一位技术分析师在学习了政府关于支付数据防火墙的指南后，与IT负责人就该指南进行讨论。采用沟通框架和 GPS 概述法进行构建：
背景：我认真了解了新信息安全政策。 意图：我们必须有所行动。 关键信息：我们的防火墙不再符合要求。 目标：新行业规范要求所有商业交易必须有5道防火墙，以确保支付数据的安全。 问题：我们当前的软件只能提供4道防火墙。 解决方案：我们必须制订软件升级计划并且提交领导层审批。 然后进行组合：「我认真了解了新信息安全政策。我们的防火墙不再符合要求，我们必须有所行动。新行业规范要求所有商业交易必须有5道防火墙，以确保支付数据的安全。可是我们当前的软件只能提供4道防火墙。我们必须制订软件升级计划并且提交领导层审批。」
这样就是一个非常优秀且高效的沟通方案。
这是一种实操性相当强的沟通技巧 在本书的后半部分，则介绍了多个主题的沟通法则，以及在发邮件、邀请函和主持会议等等场景下如何利用这种沟通技巧。 包括结尾还精心准备了一些场景和习题让读者练习。 总体来说，通过书中的多个案例分享和实操指导，能够感觉到是一种可以快速应用到实际工作中的技巧。 真正应用起来的话，我感觉难点主要还是在考验自身概括与凝练的能力。 如何通过寥寥数语能够让沟通双方对于接下的解决方案有一个共性的认识而不产生误解，这也需要多加修炼。</description>
    </item>
    
    <item>
      <title>【把书读薄01】拼凑真相：指导读者如何面对各种诡计多端的媒体把戏</title>
      <link>https://www.xzywisdili.com/post/2022-08-29-bookreview01/</link>
      <pubDate>Mon, 29 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2022-08-29-bookreview01/</guid>
      <description>总结 《拼凑真相》提出了 10 条所谓的数据法则，在我看来只有 6 条比较实用； 书中使用了很多历史上的事例作为论据，但是对于每种观点的详细论证不够； 《拼凑真相》评分：3.0/5.0，不推荐专门抽时间阅读。 在现今的网络时代，各种传统媒体和自媒体生产的观点层出不穷。这其中的大多数都是为了调动读者情绪，进而博取流量的错误观点。低端一点的可能仅仅是利用聊天记录和阴谋论炮制观点。高端一点的就是通过参杂数据和统计分析，看似在理，实际上则通过部分手段营造假象。《拼凑真相》这本书就是在引导读者，在面对这些纷繁的数据观点时，如何做到距离真相更近一些。
十大法则其实只有 6 个比较实用 《拼凑真相》这本书的副标题是「认清纷繁世界的十大数据法则」。但通篇读下来，感觉只有 7 个比较实用。
控制情绪、放下个人偏见。有时候看到与自己观点相符的分析结论，就会更容易偏信而忽略其中的问题；看到相悖的观点则反之。这时候需要先平复心情，放下偏见地去审视结论的得出过程是否有漏洞； 举例：习惯喝咖啡的人群了解到咖啡的相关健康风险时候，第一反应偏向于不太相信。
慎重结合自己个人经验。如果遇到和自己个人实际体验不一致的情况，不要轻易采信任何一方，而是分别审视官方的数据来源和统计方法是什么，我自己的个人体验是否有局限性。 举例：自己乘公交车十分拥挤，但是官方表示平均乘车人数不是很高。可以审视自己乘公交车是否集中在某个时段，官方统计的时段区间是什么。
确定每个统计量背后的准确含义。这一点非常重要。通常我们会看到一些陌生的统计量，或者比较空洞的大词，不妨调查一下这些词的准确含义是什么。 举例：同一个统计量“新生儿死亡率”可能在不同的城市或者医院，由于对新生儿的定义（周数）不同，导致最后的统计数据也发生了差异。
注意指标之间是否有可比性。某些统计量之间并不能直接比较，强行比较当然会带来错误的结论。 举例：比较城市A和城市B的相对安全性，因为两个城市人口密度不一样，不能直接用凶杀案数量比较。而用一个比率，比如每百万人的凶杀率更合理。
考虑统计样本是否全面，理解幸存者偏差。部分样本由于某些原因根本没有发声的机会，导致能让你看到的是特定的一批样本。读者可以反问：有没有漏掉一些样本？ 举例：记者到候车大厅采访大家有没有买到返乡的火车票。
不要迷信大数据和相关算法。大数据在大多数情况下算法和数据来源并不透明，而小数据统计往往更容易进行核实和检验。 举例：谷歌的流感趋势预测，仅凭算法预测流感发生趋势，但是却错误地将“冬季球赛”的检索和“流感发生”进行了错误关联，并且没有剔除，导致后期的一些预测发生了较大误差；
最后作者表明了：
图表是双刃剑，容易通过别有用心的设计产生误导； 提倡让民众自发产生好奇心，学习相关的专业知识，具有一定的判断力； 同时关注官方统计机构发布的相关数据和结论，保护捍卫统计公正性的学者，唾弃那些故意哗众取宠、操弄数据的“假科学家”。 但是很明显，作者没有讲解图表常用的误导方式。而后两点也更像是作者个人政治观点的主张。从读者的角度来说，并不具有很强的实操性。以至于让我觉得，可能只是单纯地想要凑齐 10 条法则这个数，而强行找补的内容。
应用到实际中的手段：批判式提问 读完此书，我认为之后再遇到一些观点的表述时，最好用的方法就是：批判式提问。
举个例子，当我们看到这样一条：「经过对学生的数据分析，我们发现喜欢吃椰子的学生的成绩比较好」的时候，我们就不会轻易相信，而是可以一步步提出以下问题：
喜欢吃椰子的定义是什么？按照食用频率？ 成绩的定义又是什么？语数外成绩？还是水果知识大赛成绩？ 学生数据的样本是什么？随机抽取的某所学校？还是椰子学园的学生？ 统计方法是什么？是否有影响成绩的其他因素？是否控制了这些因素？ 我身边的生活经验，是否存在这样的现象？上述结论和我的生活经验有何异同？ 只要能够多思考，多提出问题，再去找原来观点的“茬”，我想应付绝大多数自媒体的信口胡诌，应该是绰绰有余了。</description>
    </item>
    
    <item>
      <title>一天内数据分布的可视化</title>
      <link>https://www.xzywisdili.com/post/2022-07-28-timeseriesplot/</link>
      <pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2022-07-28-timeseriesplot/</guid>
      <description>我们在很多情况下都会想要可视化一天中的周期时间来探索发现可能存在的某种模式。 比如根据犯罪数据发现在一天中的高发时段，又或者某个app的用户活跃时段的表示，又或者患者在院外一天中的健康作息的可视化，都不可避免会碰到要把数据在周期性的时间上进行展示。 而目前这样的可视化方向大概有两个：线性展示和环形展示。
线性展示 线性展示是目前使用方式相对比较多的可视化方式，如下图分别展示的对于人群购物时间的可视化和运动传感器回收数据时间分布的可视化：
如此使用折线图和条形图来对数据在一天中的时间分布的优势显而易见：
符合读者的直觉； 绘图比较简单； 但是这种方式也有一些局限性，即没有办法很好体现出时间的连续性。 它们的 X 轴出于限制，都不可避免地选择两个时间点作为图表的开始和结束。 而这个时间点的选取也需要根据数据的实际情况来进行。 比如通用的时间制会规定一天的24小时开始于 0:00，结束于 23:59，但对于很多活动并非如此（比如部分职业的加班或者犯罪往往在午夜时分保持连贯，甚至有可能延伸到凌晨2-3点）。 有时候图表所显示的内容强行断开有时候也会让部分想要探索该处连续性的读者没有办法直观看到。 此外，大众对于上午、下午、徬晚和晚上都在心里有一个普遍共识的观念，这也没有办法在线性图中直观看到，除非作图者显性标注出来。
以上这些种种的问题想要解决其实比较棘手。曾有人使用双层时间图来进行展示：
上半部分依然是正常的线性可视化，但是作者将上半部分反转再进行平移，想要以此来同时展示白天（上半部分）和夜间（下半部分）的时间趋势，从一定程度上解决连续性表现不足的问题。但是这样在一定程度牺牲了可视化的直观性，用户可能会觉得上下是两个系列的数据；另外也没有从根本解决问题。
所以有些人开始尝试另一种可视化思路。
环形展示 不知道环形展示方式的最初灵感是不是来自钟表的表盘。但钟表代表时间，使用钟表表盘式的圆形尝试来进行一天内趋势的可视化似乎也合情合理。 我自己也在 Excel 里面尝试了一下。 只要将数据转换合理，再使用 Excel 里面内置的雷达图，就能做出近似环形的可视化效果。 但是很快就发现了问题：传统的符合人类直觉的钟表表盘是 12 小时制的，而一天有 24 个小时。 如果强行将 24 个小时挤入一个环形圆盘也会显得非常怪异，比如 Magic Eye 的设计中，&amp;ldquo;Morning&amp;rdquo; 到了右下象限而 “Evening” 到了左上象限：
这时候有人开始尝试这些妥协式的设计，即使用双表盘、在一个表盘中利用不同颜色来展示上12小时和下12小时、又或者用内圈和外圈来代表 AM 和 PM：
甚至还有一种使用无限符号的可视化方式，想要表现完整的一天：
可以看到，环形的方式进行可视化展示的优点包括：
能够带给读者直观的“上午”、&amp;ldquo;下午&amp;quot;以及“晚上”这种结合生活时间段的感受； 部分解决了连续性的问题； 但是又带来了新的问题：
AM 和 PM 本身需要颜色或内外圈多维展示，如果有更多维度或系列的数据，就会显得更加杂乱； 作图难度相对于线性方式来说更高； 数据映射到极坐标下，增长和减少的趋势可能也会随之扭曲。 综合以上，我觉得还是优先考虑使用线性的方式进行展示一天内的数据分布情况更为合理。 更为简便的作图方式，展示作图者想要展示的趋势或者模式，就已经足矣。 如果使用环形可视化很容易耗费更多的精力，反而只能做到华而不实的效果，也可能被误导，很难真正探索出数据背后真正的时间分布情况。</description>
    </item>
    
    <item>
      <title>2022 跨年快乐</title>
      <link>https://www.xzywisdili.com/post/2022-01-04-happynewyear/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2022-01-04-happynewyear/</guid>
      <description>感谢 CXW 同学的邀请，能一起在跨年那天晚上看一场现场的爵士大乐团演出。超棒的音乐，超棒的食物和环境，送走 2021 的最后一天和新的 2022 年（当然今天才发，一定不是因为我太懒哈哈）。
这样的爵士演出如果用两个字总结就是「惬意」。所有乐手似乎都有一定的自由度，但又似乎紧紧地联系为一个整体，构成整个和谐的舞台。就好像跳舞的舞者，每个人可以有自己独特的动作，而且组合在一起依然赏心悦目。同时，表演的不同曲目又给到了不同乐手的 solo 段落，其它乐手作为陪衬。轮流表演，相辅相成，实在是太有趣了。就这样一首接着一首，时间飞速流逝……
我也想到了过去几年的跨年，都是和 LXZ 同学出去到一家固定的日料店，吃到将近关门。这似乎也成为了近几年的保留节目。每次跟他的畅谈都能感受到他的一些坚定的力量，也让人对生活还是抱有热情。2021 毕业虽然分道扬镳，也照例第一时间问好。也希望他 2022 一切都好。</description>
    </item>
    
    <item>
      <title>读完一本应试方法书的碎碎念</title>
      <link>https://www.xzywisdili.com/post/2021-12-18-bookthoughts/</link>
      <pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-12-18-bookthoughts/</guid>
      <description>从一本书说起 最近的机缘巧合之下读到一本书，叫《如何成为一个会学习的人》。 一来每隔一段时间就需要读一读这种方法书打打鸡血，二来也听说日本人写这种书是有一手的。 但读完还是比较失望的，除了作者一句话一段的叙述方法和他缺少论证某种方法有效的逻辑之外，最大的缺点还是介绍的绝大部分方法基本还是陈词滥调。
其中作者最核心的观点是要找到学习的乐趣，让自己沉迷其中，然后能够全身心专注其中。之后展开的各种方式都是围绕这一个核心所展开的。 这个核心虽然表面听上去无可指摘，但是实际上在东亚的此类应试教育中真的太难应用了。 除去少部分学霸人群之外，绝大多数的人在面对语数外理化生史地生等等数门课时，几乎很难对每一门都感兴趣。 可能一部分人只对其中某些课感兴趣，成为偏科的学生；而甚至有人所有课都不感兴趣，这样的话在学校里学习当然是一件极为痛苦的事。 当然，我的意思不是说这些学生是有问题的，相反，我觉得现在的课程安排可能需要一些思考。
我所畅想的课程安排 可能很多人在上学时都或多或少想过这样一个问题：我学的这些未来会有什么用？而大部分的老师会告诉你“不要想这些乱七八糟的”。 甚至我还听到过“无用之用，方为大用”这样的玄学说法。但经历了初中高中到大学毕业，我感觉到的事实就是，当初上学学的很多课，是真的没有用、用不到的。 如果教育的目的是让一个人成为自我完整的人、对社会有用的人，我个人认为以下这些课是最重要的：
写作与表达**：主要是教导如何通过口头和书面准确通顺地表达自己的意思，能够让读者清晰地获取信息； 情绪和压力管理：让学生可以感知到自己现在的情绪和可能面对的压力，并且能够自我控制； 人体和健康基础：基础的医学健康知识，了解真正健康的生活方式； 性教育和两性关系：正确的性别生理知识和性别观念，以及男性和女性良性相处的相关观念； 体育运动：绝对不可缺少的一环，学生应该获得足够的户外体育活动时间； 思想品德：一个善良、正义的人的必备素质； **逻辑学基础 数学基础 英语 这些是我认为一个人应该提前学到，并且会受益终生的内容。所有这些在步入社会都能用的到。相反，这些在现在的教学安排是极为匮乏的，体育运动仅限于课间跑操和一周两节的体育课。 健康的两性相处观念和基本的逻辑教育完全缺乏；而在未成年人抑郁和自杀的增加的同时，情绪和压力管理也没有跟上。诚然，这些项目都很难考核，也不适合现行选拔性考试的应试教育； 也许我的这些想法也像是痴人说梦。但我真希望有一天我们真的不需要这样的应试教辅书和方法书了。</description>
    </item>
    
    <item>
      <title>最近在尝试的一种新的减重饮食法</title>
      <link>https://www.xzywisdili.com/post/2021-11-29-newdietmethod/</link>
      <pubDate>Mon, 29 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-11-29-newdietmethod/</guid>
      <description>最近看到了一种新的减重饮食方法（本身不是很新，只是我最近才看到），感觉容易执行且负担并不是很大，所以打算开始试试。这种饮食方法是间歇性断食，简称「轻断食」。其主要分为两种类型：
限时进食：即每天只在有限的几个小时内进食，比如「186 断食法」等 全天断食：即定期断食一整天，比如「52 轻断食」等 可以说，全天断食是比限时进食更进阶的一个版本，其中最有代表性的就是「52 轻断食」，即一星期当中任选不连续的两天控制饮食，轻断食的那天，女性最多摄取 500 大卡，男性则最多摄取 600 大卡。所以，所谓「断食」的含义并不是不进食，而是在原先的饮食结构上，进食更少的分量。并且也不只是单纯依赖断食减重，还是需要定期进行运动，增加热量消耗。
这种「轻断食」和传统的饮食减重方式相比，优势主要有以下三点：
对比持续节食：当你吃得太少，饮食摄取热量低于身体基础代谢率时，身体就会启动保护机制，减少不必要的热量消耗，降低基础代谢率，同时身体还会燃烧肌肉来获得能量，导致肌肉的流失；而肌肉的流失又会降低基础代谢率，形成连锁反应，也就造成「易胖体质」；而轻断食可以摄入足够维持基础代谢的热量，再通过运动等使每日活动热量超过基础代谢率，身体便会燃烧脂肪进行减脂； 对比低糖饮食：低糖饮食虽然能达成减肥效果，但是长期执行可能对身体造成伤害，尤其当身体缺乏糖分时，脂肪无法正常燃烧会产生酮体，而大量酮体不但对大脑有伤害，对心脏、肝脏和肾也会造成损害；而轻断食提倡保持均衡饮食结构，糖分也会正常摄入，可以长期持续保持； 对比白开水断食、流体断食和蔬果断食等：轻断食保持均衡的饮食结构，包含全类食物和六大类营养素的全面摄入，不用特别禁食某种食物； 这种饮食方法简单且更有吸引力，能够长期执行，参与者也更容易坚持和保持这样的饮食习惯，比如在一周中比较忙碌的两天，就可以尝试这样的饮食方法。 而在「52 轻断食」的基础上，有对饮食结构更加明晰的「12345 饮食法」，即正常饮食的 5 天里：1 餐 500 大卡，其中蛋白质占 25%、淀粉 35%、脂肪 40%。这里每一项的具体含义如下：
一餐 500 大卡：一天的总热量就控制在 1200-1500 卡以内，可以维持身体的基本新陈代谢，再搭配运动消耗热量燃烧脂肪，就能变瘦； 25% 的蛋白质：可以避免肌肉流失，尽量选择优质低脂蛋白质，比如鸡蛋； 35% 的淀粉：吃对糖比不吃糖更能维持减重效果而且健康，但此处糖并非精制糖类，推荐吃全麦类淀粉； 40% 的脂肪：保证身体需要的必需脂肪酸，帮助稳定血糖，增加饱腹感。 而在需要轻断食的两天里，将原先的一餐，分到整天吃，就可以保证一天只摄入 600 大卡。当然，想要减重不单单只依赖饮食，同时需要进行充足的运动。 我已经准备开展「52 轻断食」减重实践了，目前选定周一和周六进行断食。希望能坚持下去取得好的效果。</description>
    </item>
    
    <item>
      <title>听完数字疗法产业峰会北京站的一些想法</title>
      <link>https://www.xzywisdili.com/post/2021-10-18-thoughtsofdtx/</link>
      <pubDate>Mon, 18 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-10-18-thoughtsofdtx/</guid>
      <description>上周五的时候，我去旁听了数字疗法峰会北京站的一些分享。数字疗法是今年兴起的一个新的行业，蕴藏着无数的机会和可能，当然也已经有很多的公司已经投身于此，做出了一些产品。听完了这次的分享，我有以下三点感想：
1 目前赛道的产品瞄准的方向比较集中 目前做数字疗法的公司很多都在做关于脑科学、认知科学和解除成瘾方面的一些诊疗工具。 比如通过移动 APP 里的认知小游戏来对患者的认知状态进行评估，或是通过软件来对已经患有相关疾病的患者进行辅助治疗。 而检索国外的产品也发现，目前数字疗法也多集中于认知科学领域和控制糖尿病人血糖方面。这一方面说明可能数字疗法确实在这些领域取得了一定的效果，也有可能说明数字疗法在其他种类疾病的辅助诊断和治疗方面的开拓依然不够。
2 目前展现产品已初具雏形，但仍需要打磨 能够发现目前展示出来的产品已经能够投入到临床的使用，但我认为还是有进步的空间。 比如针对不同的患者，如果提供个性化的数字疗法方案；如何利用已覆盖的患者数据和结局来对产品进行快速的更新迭代；如何有效地将患者家属和医生的参与感提高并调动起来，这些方面依然没有看到更多的进步。
3 「数字疗法」的大众认知程度和普及度不高 这一点尤为明显。当我告诉同为医学硕士或博士的同学的时候，他们都不由得反问：「什么是数字疗法？」更遑论普罗大众了。「数字疗法」这个名词目前在国内市场的大众认知程度和普及程度并不高，这样一定会导致大家对其的接受程度依然不高。这一方面可能需要各家公司通力协作进行一定时间的市场教育，另一方面在做此类产品的时候可能需要改一个更加通俗易懂的名词。
「数字疗法」的时代可能才刚刚到来，十分希望看到有更多的人投入到这一领域，有足够有效且漂亮的产品问世，非常期待 。</description>
    </item>
    
    <item>
      <title>看看一些现代“媒体”是怎么愚弄大众的</title>
      <link>https://www.xzywisdili.com/post/2021-08-13-seehowmediafoolus/</link>
      <pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-08-13-seehowmediafoolus/</guid>
      <description>见识到了有人如何通过玩文字游戏吸引流量了。
从一则新闻说起 昨天半夜在微博上看到了这么一则新闻：巴黎奥运会将削减一些项目，帆船、竞走、棒球、空手道和拳击都将面临删减和调整，同样也包括4个举重项目。
但是这个新闻经过一些媒体和大V之口就变成：「巴黎奥运：取消多个中国夺金热门项目，新增霹雳舞」。再经过微博大 V 一转载，事情的逻辑就变成了：中国在东京奥运举重表现出色，于是小心眼的西方国家们嫉妒，于是法国主谋取消了举重项目。这也激起了很多网友对法国进行辱骂攻击。
但我觉得奇怪，就简单检索了一下：
首先，这事并不是新闻，而是去年12月就已经提出，时间顺序上就驳斥了中国举重队在东京奥运斩获数枚金牌和削减举重项目的因果关系；其次，取消原因也和中国此次奥运举重队的傲人成绩并无联系，主要是国际举重协会管理之混乱程度令人咋舌：
内斗严重，曾经出现过 3 天更换 3 个主席的荒唐事，遭到了国际奥委会的多次警告； 兴奋剂审查不力，18 名举重运动员通过他人冒名顶替逃避检测 贿赂裁判和相关官员，举联主席都带头腐败，1040 万美元现金无法解释 通过这几份公开报道，足见国际举联已经烂到根上，引起了国际奥委会的强烈不满。基于这样的背景，国际奥委会早有提议在巴黎奥运会上削减举重项目。
有人可能要问：那为什么最近这则新闻又被拿出来了？
这是因为国际奥委会最近投票通过了一项关于《奥林匹克宪章》的修订，简单说就是扩大了自己的权力，当发现某项体育类别的管理机构问题很大时，就可以削减或者取消这项运动以示惩戒。
当然，这整件事对于我国和我国运动员都是不利的，因为举重确实是我国的传统强项。但我想就算网友们感到不满，也应该搞清楚事件的来龙去脉，或许可以攻击国际举重协会管理混乱，甚至攻击国际奥委会的一刀切制度不合理。但是对法国人和巴黎奥运会进行辱骂这点上，实在是骂错了人。
警惕媒体和大 V 对于新闻的「加工」 东京奥运会期间爆发了不少全民关注的热点新闻，也有不少新闻闹出了这样那样的「乌龙」或者「反转」，但其实我觉得这主要有几点原因：
媒体和大 V 二次加工新闻：主要表现在修改大标题、断章取义、强行联系。保持新闻的客观中立已经不再是这些媒体恪守的信条，怎么样博取流量，尤其是利用大众情绪博取流量才是他们最在意的。大众想要看到什么，他们就炮制什么样的新闻，至于被事实打脸或翻车也不会伤筋动骨，因为网友的关注焦点一下子就过去了； 大众已经深陷信息茧房：这点我深有体会。因为检索上述新闻消息根本不需要任何难度，直接用相关关键词在百度或者谷歌检索，就能看到过去的新闻稿。这说明了现在获取资讯的网友越来越懒于去探求事实，“不就是一则新闻嘛，他发出来了，我跟着骂两句，也就刷过去了”。可能大部分人抱着这样的心理，但殊不知自己的潜意识和观念已经被这些媒体通过这样的方式塑造成了另一种样子。 过去我们常说互联网万物互联，透过「窗户」就能看到世界。但其实警惕，有人在你看出去的那扇窗户上捣鬼，只给你展示你想要的。</description>
    </item>
    
    <item>
      <title>在 2021 年寄一封平信</title>
      <link>https://www.xzywisdili.com/post/2021-07-05-writesendletter/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-07-05-writesendletter/</guid>
      <description>昨天因为一些原因，也体验了一把在 2021 年寄一封平信的整套流程。 正好值此毕业之际，给家里的爸爸妈妈写一封感恩家书。 先找了一张信纸然后按照打好的草稿誊抄了一遍（写字练字养成正确的书写姿势实在是太重要了， 不然就会像我一样写三四行，手便会非常酸痛）。
昨天下午，带着信纸去到了旁边的中国邮政，下午大厅里空空荡荡的，没有一个顾客。 在保安对我例行测体温扫健康码之后，一位工作人员非常热情地招待了我。 得知我要寄平信之后，也直接给我取了一个信封和邮票。
最后算上称重从北京寄回陕西，总共花费了￥1.3。当然，寄平信的花费是必须使用现金，不能用电子支付的。
在互联网的发展和对信息发送接受速度的追求下，确实能感觉到寄信这件事已经快要淡出社会的舞台了。 明明在我小时候还司空见惯的东西，到 2021 年，竟然从写信到贴邮票都带有一种复古感，让我还是觉得有些奇妙。 不过，我觉得偶尔摆脱互联网，在线下进行一些实际的任何活动，也确实能体会到生活在这个社会的实感。 这种实感还是挺重要的。</description>
    </item>
    
    <item>
      <title>我个人不会再买的东西</title>
      <link>https://www.xzywisdili.com/post/2021-07-02-thingsneverbuy/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-07-02-thingsneverbuy/</guid>
      <description>我平时算是少数派的忠实读者，但仍觉得 少数派的编辑好物推荐栏目有过度倡导消费主义的嫌疑。 当然，这绝不是对少数派本身立场的任何批评，因为豆瓣消费降级小组和 豆瓣不要买小组也都是从该网站接触到并受益良多。 抵抗消费主义，只购买自己需要的东西是我个人坚信并践行的生活方式。 接下来也简单列出我个人不要购买的一些物件，顺便也使用一下久违的 Markdown 表格。
物品 理由 含糖饮料 皮肤会变差，浪费钱，游离糖对身体不好 瓜子 嗑起来就什么都做不了，肠胃容易难受 实体书 慎重，非必要不要买，搬家巨麻烦（电子版代替） 纸笔本 用的少了，大学攒了很多，搬家的时候都要丢掉，没必要添置 手机游戏月卡 提供体力和原石的虚拟资产没有意义（迟早会弃游） 小麦欧耶 容量和营养价值对比，溢价太高，口味也一般 免洗手消毒凝胶 好用，但贵，可以用香皂代替（可以用很久） 手机壳 一套足矣，不要喜新厌旧买很多 自热火锅 口感一般，吃一次房间味道很重，油腻 奶茶 / 茶饮 溢价，并不健康，容易腻 线上买课 善用检索，看看是否有公开分享的免费替代版本 至于想要的东西，之前有个清单，但也删的几乎不剩了。 一个纠结的点是耳机。曾经室友推荐我购买的一条森海塞尔 MX375 已经用了 5 年仍然正常服役， 而且真的对我来说完全称心如意的一条耳机。但现在无线耳机大行其道的今天，逼着你必须购置一对无线耳机。 之前购买的 Redmi 的无线佩戴起来有些不适，但先用着吧。可能在遥远的未来再换掉。
另一个纠结的点就是手头这台 15 mid 的老 MBP。也算服役了5年半，虽说还能用，但是运行速度和功耗发热 都明显处于“老年”状态。也是实在纠结该拿他怎么办。等之后找到一个合适的契机更新吧。
别的真就没有什么想买的了。</description>
    </item>
    
    <item>
      <title>最近要开始啃书了</title>
      <link>https://www.xzywisdili.com/post/2021-06-28-starttoreadbooks/</link>
      <pubDate>Mon, 28 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-06-28-starttoreadbooks/</guid>
      <description>最近开始关心 AI 技术在医疗领域的一些应用。 随着老龄化社会的进程，节省医疗系统的冗余成本，做到更好的健康管理势必更为重要。 而从现有积累的和未来获得的人群大数据势必也将把医疗探索和相关制药研发带入到一个新的时代。
但同时这个进程也有太多问题和阻碍：缺乏相关跨界人才的问题，数据隐私和伦理的问题，模型可解释性的问题和 人群对 AI 的信用度和接受度的问题等等……
不过，我还是相信，新技术的到来能帮助我们在医疗系统中解决更多的问题。
所以，最近搜罗了这个方向的一些书籍，准备开始爆啃：
当然，如果有更多的心得和收获也会在博客和大家及时分享。 可能唯一的遗憾是平时没有一起交流讨论的伙伴。</description>
    </item>
    
    <item>
      <title>如何从 NASA 下载气象数据</title>
      <link>https://www.xzywisdili.com/post/2021-06-16-downloadclimate/</link>
      <pubDate>Wed, 16 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-06-16-downloadclimate/</guid>
      <description>如果大家有从 NASA 获取气象数据的需求的话，只要在某度搜索，一定会看到下面的这些链接：
他们可以批量获取单个城市和经纬度范围内的数据，而且代码也写得很好，但有两点问题：
他使用的数据库是 NASA 为作物生长模型提供的气象数据，包括辐射、最大最小气温、降雨、风速，而不包括很多研究需要用到的气温和相对湿度的数据； 他将空值用了前后5日的平均值代替，有时候可能不需要这么处理 针对以上两点问题，我只能去寻找 NASA 官网进行数据检索和下载，而 NASA 提供的数据获取工具也十分方便。 只需要打开 NASA 的 Data Access Viewer，就可以看到左边的界面：
左边的工具选项都十分明确：
数据来源：就选择“SSE-Renewable Energy”就好； 选择日值、年值或是气候学的平均处理； 选择目标城市的经纬度即可，当然也可以使用标记工具直接在地图上点出； 输入目标的起止日期； 输出文件的格式 下面就是选择目标变量，我选择的是这两个，也就是气温和相对湿度：
接下来就可以提交和下载了。
至于数据的说明，可以点击这里，里面说明了数据的来源、分辨率和可获取的日期跨度。当然，如果要进行批量获取的话，可能需要高人来写相应的代码了。</description>
    </item>
    
    <item>
      <title>从电子病历提取数据</title>
      <link>https://www.xzywisdili.com/post/2021-06-15-extractnumbers/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-06-15-extractnumbers/</guid>
      <description>电子病历的普及度已经很高。但如何从电子病历中提取信息还是比较令人头疼。 首先病历内容众多，从主诉到体格检查，从家族史到用药史，一份完整的病历涵盖的信息众多。 其次，病历内容是由医生按照段落填写的，很难在数以万计的病历中找到通用的标准进行提取。
当然，如果医院的病历系统是按照表格进行组织并且保存，比如我之前实习过的社区医院，将每个人的电子病历 保存为 HTML 格式，就可以使用 python 的 BeautifulSoup 进行提取。当然，如果只能得到大段 文字的话，大概需要借助人工智能里面的自然语言处理来做更多的工作的。
当然，如果任务比较简单的话，我们还是有取巧的方法的。比如要从病历记录里面提取出来身高、体重、收缩压和舒张压 等等，如：“血压114/56mmHg，体重53.3kg，胎心146次/分，宫高25cm，宫缩无。” 这样的描述中提取出舒张压：56，收缩压：114，体重：53.3 等等数据，我们可以借助正则表达式解决：
library(readxl) library(tidyr) library(stringr) data &amp;lt;- read_excel(&amp;#34;data.xlsx&amp;#34;, sheet = 1) extract_blood_pressure &amp;lt;- function(diag_str) { res &amp;lt;- str_match(diag_str, &amp;#34;血压[:： ]*[0-9]*/[0-9]*[ ]*[(mmHg)|(mmhg)]+&amp;#34;) blood_pressure &amp;lt;- unlist(str_extract_all(res[, 1], &amp;#34;[0-9]+&amp;#34;)) return(as.numeric(blood_pressure)) } extract_height &amp;lt;- function(diag_str) { res &amp;lt;- str_match(diag_str, &amp;#34;身高[:：]*[0-9]*/[0-9]*[ ]*[cC][mM]&amp;#34;) height &amp;lt;- unlist(str_extract_all(res[, 1], &amp;#34;[0-9]+&amp;#34;)) return(as.numeric(blood_pressure)) } extract_weight &amp;lt;- function(diag_str) { res &amp;lt;- str_match(diag_str, &amp;#34;体重[ ]*([0-9]{1,}[.]*[0-9]*)[ ]*[kK][gG]&amp;#34;) weight &amp;lt;- unlist(str_extract_all(res[, 1], &amp;#34;[0-9]{1,}[.</description>
    </item>
    
    <item>
      <title>新发现的 R 里关于 data.table 的一些神奇用法</title>
      <link>https://www.xzywisdili.com/post/2021-06-15-newrtips/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-06-15-newrtips/</guid>
      <description>R 语言中的 data.table 包可以理解为 data.frame 的高级版本，它比较适合适合用来处理大型数据集。
载入包并且读取一些数据，当然也可以使用 nrow 参数来决定读取多少行：
library(data.table) mydata &amp;lt;- fread(&amp;#34;some_kind_of_data.csv&amp;#34;) mydata &amp;lt;- fread(&amp;#34;some_kind_of_data.csv&amp;#34;, nrows = 10) data.table 包提供了一个非常简洁的通用格式：mydata[i, j, by]，可以理解为：对于数据集mydata，选取子集行i,通过by分组计算j。只需要记住，i是用来在行上进行操作的（比如筛选行），j 是用来在列上进行操作的（比如选择列或者根据计算创建新列）。对比dplyr等包来说，data.table的运行速度更快。
选择列 如果只需要选择列的话，可以只代入 j，但需要记住给 i 留出位置：
mydata[, j] 首先，通过列名选择列是，是否需要打双引号是一个值得考虑的问题，因为两者各有优劣。 data.table 支持打双引号的原生 R 的做法：
data1 &amp;lt;- mydata[, c(&amp;#34;columnA&amp;#34;, &amp;#34;columnB&amp;#34;, &amp;#34;columnC&amp;#34;, &amp;#34;columnD&amp;#34;)] 但也可以使用不打双引号，这样会更方便（就好像 tidyverse 里面的 select），只不过需要用到 list：
data1 &amp;lt;- mydata[, list(columnA, columnB, columnC, columnD)] 这里，第一个小技巧就来了，我们可以使用一个点代替 list：
data1 &amp;lt;- mydata[, .(columnA, columnB, columnC, column)] 在 data.table 的中括号里，.() 就是 list()的简写形式。
如果你想使用一个已经存在的列名向量，比如：</description>
    </item>
    
    <item>
      <title>对数据进行填补</title>
      <link>https://www.xzywisdili.com/post/2021-06-09-mergeandkeepdata/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-06-09-mergeandkeepdata/</guid>
      <description>今天整理数据的时候，需要使用数据集 2 对数据集 1 里缺失的部分进行填补，而两者重复的部分，优先保留数据集 1 里的。
这个问题其实很简单，只需短短 2-3 行：
result &amp;lt;- data1 %&amp;gt;% left_join(data2) %&amp;gt;% mutate(value = ifelse(is.na(value.x), value.y, value.x)) 但我遇到的问题稍微多一点点难度，日期的序列不是连续的话，例如数据集 1：
# date value # 2014-01-01 12 # 2014-01-03 14 # 2014-01-05 17 数据集 2：
# date value # 2014-01-02 13 # 2014-01-03 16 # 2014-01-04 15 那么希望得到的结果是：
# date value # 2014-01-01 12 # 2014-01-02 16 # 2014-01-03 14 # 2014-01-04 15 # 2014-01-05 17 我们会需要先生成一个日期的模板：
template &amp;lt;- tibble( date = seq(as.</description>
    </item>
    
    <item>
      <title>毕业流程之不吐不快</title>
      <link>https://www.xzywisdili.com/post/2021-06-09-graduation/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2021-06-09-graduation/</guid>
      <description>终于在今年经历了毕业季，虽然坎坎坷坷，但也还算顺利，即将要从北京大学医学部毕业了。 然而在这之间走的各种流程和细节着实让人无比心累，实在是不吐不快。 明明有很大的提升空间，却还是抱残守缺，实在是与北大医学部的名校形象不太相符。
老旧的线上管理系统 难以想象，北医在 2021 年还在使用只有 IE (对，就是那个在 95 年推出，在 15 年被微软宣布要放弃的 Internet Explorer 浏览器) 才能顺利登陆并且完成各项内容提交的研究生教育管理系统。只要使用现代浏览器登陆，那必然是只能显示一片白色：
这带来的后果便是，从抢课、查成绩，到毕业申请、提交材料，任何使用苹果 mac 系统和最新版 windows 的用户都 无法顺利处理研究生期间的教务相关事务。虽然北医的生活服务平台已经更新成了现代化的新版应用，并且支持所有平台（包括手机 APP），但研究生教育管理系统迟迟不更新的原因实在不得而知。
另外，一级二级菜单混乱，反应延时，信息显示不清晰直观等问题就不在这里一一赘述。
行政人员的办公方式和态度槽点繁多 这一点应该是绝大部分毕业生的共识。毕业所需程序复杂，材料繁多，行政人员准备了一份 100 多页的 PPT 来解释说明全程。 整个文件字号大小无区分，找不到一级二级标题，各种颜色色块堆叠，实在让人无法找到重点。就从这一页上来看，目之所及 5 种颜色。想要完整清晰地领会这页的意思，应该是要花费不少时间：
如此复杂繁琐，难以理解，想必很多学生都有问题要去询问相关的行政人员。但相关人员态度敷衍，摆脸色， 有时候明明可以直接告诉你问题的答案，就是不说，让你自行去查 PPT。而到最终收材料的那天，每个人需要上交 10 多份纸质材料。没想到两个行政人员对每个同学每一份文件逐一检查，队伍直接排到了走廊尽头。整个排队流程至少要让你等待 1 个半小时！我在想，如果找一间会议室，按照要交的文件分流成列，找几个本科学生检查模板化公式化的材料，行政人员去检查更复杂的提交材料。整个过程使用共享文档登记提交进度，通过一份就在该项下面打勾，效率至少比现在这样要翻几倍。
无纸化进程还很远 无纸化办公的概念一直在普及并被实现，在现今，很多手续的办理，甚至合同的签署都可以完全在线化，电子化。 然而，整个毕业流程距离无纸化办公还太远。整个流程光各种申请表格、提交材料，就大大小小至少 20 多份。 而从论文写完，送审，到答辩，再到最终提交，光纸质版的大论文都要至少打印 13 本之多。 其实，仔细想想，里面明明有很多不需要签字或者盖章的文件完全可以移交成在线电子表格的形式进行提交。 就连导师签字的内容也可以通过在线的教务系统进行审批和签字（当然，这么老旧的教育系统当然是不具备这个功能的）。
当然，这些只是我在这所学校经历最后阶段的一点感想。可能这些问题如此难以解决和实现有其背后的原因，但我还是真心 希望这所学校可以变得更好一点。</description>
    </item>
    
    <item>
      <title>推荐且收藏的好网站</title>
      <link>https://www.xzywisdili.com/post/2020-12-28-recommendwebsite/</link>
      <pubDate>Sun, 27 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2020-12-28-recommendwebsite/</guid>
      <description>这篇博客计划持续更新。这里的网站或者是实用的工具，或者是收藏的实用知识，而且每一个都是我自己用过或者看过的。 其中不少还是我高频使用的，甚至域名也已经背下来了。
工具类网站 经纬度批量查询 世界范围内免费地图下载 查看时差的网站 提供代理 ip 池 各种知名品牌配色参考 电脑装机官方网站合集 快递时效查询 深度学习助力翻译网站 DeepL 在线编辑修改 GIF 图 免费在线 OCR 工具 给定地图区域的面积和最大容纳人数 我最常用的 PDF 转图片网站 上传 word 生成手写字体文档，方便打印的【萝卜工坊】 下载无水印抖音视频 一站式解决 gif 相关问题（什么都有） 免费美区 Apple ID B站视频解析下载 看不懂的网络缩略词速查工具 学习类网站 杀手级词云 英文句式写法查询 编程通用算法可视化 和小浩学算法大全 统计类图表汇总 python3网络爬虫汇总 经济类数据图表（值得学习） 积累 Tips 科研·学术 学生在家远程学术 生活·厨房 夏日便当拯救计划 通过这些小改变，帮家中的年夜饭增添一份健康 屯粮做饭 关于洗涤、熨烫和收纳衣服的常识 工作日简单A+B煮饭 TDEE 热量计算器，得到每日摄入热量 打印机选择指南 职场·工作 写给职场新人的 PPT 演示制作指南 PPT 制作全流程要点 办公技巧分享 2020 年 7 月中华人民共和国县以上行政区划代码 其他 bilibili up主推荐 </description>
    </item>
    
    <item>
      <title>赵粤的《时尚COSMO》杂志翻译</title>
      <link>https://www.xzywisdili.com/post/2020-09-30-zhaoyuecosmo/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2020-09-30-zhaoyuecosmo/</guid>
      <description>写在前面 A little words before 我的英语水平相当有限，但我想把赵粤接受《时尚COSMO》的采访内容分享给可能看不懂中文的海外粉丝朋友。 里面有一些专用的中文词汇，如果你不明白的话，可以点击我附上的链接查看这些词语的具体含义。 如果您发现了我翻译中的问题，或者您能提供更高质量的翻译，我非常感谢。
My English is not very good, but I want to share Zhao Yue&amp;rsquo;s interview on COSMO emagazine with overseas fans who may not be able to read Chinese. There are some special Chinese words in it. If you don&amp;rsquo;t understand, you can click the link I attached to see the specific explanation. If you find any mistakes in my translation, or if you can provide a higher quality translation, I would be very grateful.</description>
    </item>
    
    <item>
      <title>聊聊《隐秘的角落》</title>
      <link>https://www.xzywisdili.com/post/2020-06-20-thebadkids/</link>
      <pubDate>Sat, 20 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2020-06-20-thebadkids/</guid>
      <description>最近热播，也引起热议的电视剧无疑是秦昊主演的隐秘的角落。而该剧的原著小说——紫金陈的《坏小孩》也和剧一起霸占了近期的豆瓣书影音热度榜前二。我作为一个紫金陈的读者，曾经对其改编剧作《无证之罪》抱以极高的评价。于是也第一时间观看了该剧，又在今天读完了他的原著小说，心情也从原先的惊喜和期待变成了失望。
不知道谁扣给紫金陈老师“推理之王”的帽子，在我看来，推理从来都不是他作品的重心。 《谋杀官员》《长夜无明》和《无证之罪》都是开头从一个非常离奇的命案开始抓住观众的好奇心，慢慢抽丝剥茧出这则命案背后的大背景和相关人物。他笔下的世界往往更偏向于丛林世界，不乏心狠手辣的恶徒，也有心怀信仰的正义之士。 在相关人物经历了一番互相争斗，周旋和算计之后，故事达到高潮，最后通过强有力的收尾让读者们纷纷意犹未尽。 他的作品风格更像美剧《冰血暴》那样的黑色犯罪片。人物塑造和多线剧情的构建也是紫金陈老师的强项。
在《坏小孩》中，紫金陈老师作出了自己勇敢的创新，塑造了一个弑父，弑友的冷酷无情，而又狡猾的少年杀手形象。 他富有情绪又善于伪装，懂得利用，狠得下心，可以想见，这样的形象在过往的中国文学中是比较具有冒犯性，也是比较匮乏的。我们可能更多会在日本的犯罪小说中看到这样的人物形象。 但是这样的创新也带来了一些弊端，紫金陈老师把大量的笔墨用在三个小孩与张东升的日常和所谓的“周旋”上。 书中人物从一开始就和盘拖出，有些行动更是显现出了狠劲，却丧失了合理性（朱晶晶和王瑶等等段落）。 最后的日记策略和严良对戏虽说挽回了一些，但是依然能看出这本书并没有发挥出紫金陈老师完全的功力。
而到了改编剧上，只能说情况变得更糟了。明显导演和编剧不能照搬小说 9 人死亡的剧情，只好在原先的框架下修修补补。 这样一来，剧作的重心偏向了对朱朝阳和严良（剧中和书中不是一个人，书中刑警为严良，福利院溜出男生为丁浩）的家庭背景展开，尤其是朱朝阳在离异父母之间的关系展开占到了大量篇幅。 最关键的是，我们的两个小少年变成了其心也善的正面形象，所有的罪恶都留给了张东升一个人。 尤其是朱朝阳抱着濒死的父亲掩面痛哭的时候，相信读过原著的小伙伴都只能无奈地摇摇头。 而我认为，这样改编的结果只能是丢掉了原著里最精华，最亮点的部分，实在让人有些失望。
但是依然也要夸奖剧作的摄影风格，给我们呈现了一座透着海风味道的沿海小城。 里面的一些镜头也颇有想法，比如第六集结尾小船透过云层，再拉回到海上浮尸的镜头让我印象非常深刻。 三位小演员的演技也是出奇地好，都表演出了各自角色的特点，在秦昊面前也丝毫不落下风。 另外，12 集的设定也应该给个大大的好评，真心不希望国产剧动辄拍出个几十集。
接下来，紫金陈老师的《长夜难明》也会出剧版，将在今年播出。兴奋地期待的同事，也希望不要改得太多，因为那本原著涉及的剧情更加阴暗，且富有政治性。希望国产剧发展得越来越好，产出更多精品。也希望国产犯罪推理类型的小说也能打出一片天。</description>
    </item>
    
    <item>
      <title>分享几篇统计相关好文</title>
      <link>https://www.xzywisdili.com/post/2020-04-28-papershare/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.xzywisdili.com/post/2020-04-28-papershare/</guid>
      <description>最近在研究分段样条回归和线性混合效应模型，看到了几篇好文可以分享。
样条回归（附 python 代码） [分段回归的拐点连续性](https://yihui.org/cn/2012/04/break-points-in-regression/ 最全使用 R 语言中lme4 包完成线性混合效应模型分析 但还是没搞懂分段线性混合效应模型，要学会接受自己的平庸和愚蠢。</description>
    </item>
    
  </channel>
</rss>
