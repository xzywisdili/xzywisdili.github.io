<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>人工智能 on XZY&#39;s BLOG</title>
    <link>https://www.xzywisdili.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/</link>
    <description>Recent content in 人工智能 on XZY&#39;s BLOG</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 03 Mar 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://www.xzywisdili.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>【把书读薄07】《所罗门的密码》：试图分析人工智能的信任问题却深度不足</title>
      <link>https://www.xzywisdili.com/post/2023-03-03-bookreview07/</link>
      <pubDate>Fri, 03 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://www.xzywisdili.com/post/2023-03-03-bookreview07/</guid>
      <description>总结 《所罗门的密码》总结了人工智能在方方面面改变整个社会的同时，可能出现的问题和挑战，并倡议出版一份《全球人工智能经济大宪章》。 书中大篇内容均是过去材料的堆叠和老生常谈的问题陈述，没有作者自己深刻的思考，和独到的见解； 评分：2.5/5.0； 推荐受众：无，不推荐任何人阅读。 作者借用了所罗门的故事，想要寓言人类社会不善用人工智能的未来。[所罗门王](所羅門 - 維基百科，自由的百科全書 (wikipedia.org))是《圣经》中的一个人物，代表着智慧。他最出名的一个故事就是“所罗门的审判”。 但拥有智慧的他误入歧途，让他建立和统治的王国深陷衰落和动荡。天才的智慧得到了浪费，并为此付出了沉痛的代价。&#xA;但我认为，单纯地用这个例子去比喻人工智能，也不是那么恰当。&#xA;从人工智能的本质去理解信任问题 目前来看，人工智能的本质，即收集数据，分析数据，构建模型。一般而言，想要得到更好的模型，需要海量，且高质量的数据。最近火爆的 ChatGPT 更是证明了这一点：当数据量足够大，同时模型参数足够多的情况下，人工智能模型能够展现出无比强大的通用语言能力。&#xA;但是，这里就引出来问题的关键：谁能同时拥有高质量的海量数据，又拥有能够驾驭这些数据的分析团队？&#xA;那就是数字行业的巨头公司，比如脸书、谷歌和阿里巴巴等。&#xA;那么，关于对人工智能的信任问题，其实就是广大用户和数字巨头之间的信任问题了。&#xA;在数字巨头提供 AI 服务，和大众用户供养数据的过程中，不可避免会产生关于以下的信任问题：&#xA;准确性与责任：广告推送可能无需很高的准确性，但医疗、无人驾驶等需要极高的准确性要求； 信息收集和滥用问题； 价值观：AI 模型的利益取向、价值观等； 其他问题 而在此过程中，由于数字巨头一开始便拥有垄断优势，在常年累月的数据积累和模型迭代后，垄断的趋势会更加强烈。这就导致对于大众用户来说，想要像选择超市商品一样更换品牌，是非常之困难的。&#xA;这就对数字巨头有着相当高的要求了：不能为了自身利益损害用户权益，不能滥用用户信息和数据，时刻对模型和算法进行监督和自查，在出现问题时承担起应有的责任……而以上的每一项对于一个商业公司来说都是巨大的显性或隐性的成本负担。&#xA;那么如何进行约束？ 这就是问题真正的困难点所在。一般而言，大家能想到的是以下两种方式，不过这两种方式都有显而易见的困难点。&#xA;通过政府或第三方对算法和模型进行监督和审核。 但是，要清楚的是，目前主流的人工智能模型，如深度神经网络，其结果的输出是「在混沌中涌现出来」的。即使是算法工程师本身，面对这个黑箱，或者炼丹炉，都无法 100% 完全参透其中的作用机制。那么也实在难以确保其中的公开透明，或者公正和准确。而且，不可否认的是，监督本身也会对人工智能的创新产生或多或少的遏制作用。&#xA;只允许人工智能给人类提供建议，真正的决策权还是把握在人类手中。 听起来很美好，但仔细想想，人类自己的认知和心智是否足够强大到，可以理性地看待 AI 的建议而不受其影响。这样是否也会隐性地左右人类的价值观和所谓的选择权？又或者这也是一种逃避责任的方式罢了？&#xA;无论如何，人工智能都已经在逐步对整个社会进行改造和重塑。但数据并非万能全面，至少价值观念、人类情感等等属性还暂时难以完美地量化。在此基础上，我们需要找到人类和人工智能的相处方式，让 AI 能够良性地辅助我们的工作和生活，而非吞噬。</description>
    </item>
  </channel>
</rss>
